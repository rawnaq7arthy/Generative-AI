{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1RDKTyHDVwZH0MvOiC2MInN9DCrwMW4TC","timestamp":1753168146914}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# üõ†Ô∏è Day 6: Agentic AI and Function Calling with LLMs - Advanced Implementation\n","\n","## Overview\n","This implementation demonstrates how to create an intelligent function-calling system that allows Language Models to dynamically select and execute Python functions based on natural language input. This is a powerful technique that transforms static chatbots into interactive assistants capable of performing real-world tasks.\n","\n","## What is Function Calling?\n","Function calling (also known as tool use) is a technique where we:\n","1. **Define a set of available functions** that the model can choose from\n","2. **Parse user input** to understand what they want to accomplish\n","3. **Let the LLM decide** which function (if any) to call\n","4. **Execute the chosen function** with the appropriate parameters\n","5. **Return results** in a natural, conversational way\n","\n","## Key Components\n","\n","### üéØ Function Selection Intelligence\n","- The LLM analyzes user input and decides which tool is most appropriate\n","- Uses context clues, keywords, and intent recognition\n","- Can choose from multiple functions or determine no function is needed\n","\n","### üîß Dynamic Parameter Extraction\n","- Automatically extracts relevant parameters from user queries\n","- Handles missing parameters gracefully\n","- Validates inputs before function execution\n","\n","### üåê Real-World API Integration\n","- **Web Search**: Find current information from the internet\n","- **Weather APIs**: Get real-time weather data\n","- **File Operations**: Read, write, and process files\n","- **Data Analysis**: Perform calculations and generate insights\n","\n","### üèóÔ∏è Modular Architecture\n","- Easy to add new functions without changing core logic\n","- Clean separation between function definitions and execution\n","- Extensible design for custom tool integration\n","\n","## Technical Implementation\n","\n","### Function Registration System\n","Each function is registered with:\n","- **Function signature**: Name and parameters\n","- **Description**: What the function does\n","- **Parameter specifications**: Types, requirements, examples\n","- **Usage examples**: How the function should be called\n","\n","### LLM Decision Engine\n","Uses GPT (or similar) to:\n","- Analyze user intent from natural language\n","- Map requests to appropriate functions\n","- Extract parameters intelligently\n","- Handle edge cases and ambiguous requests\n","\n","### Execution Pipeline\n","1. **Input Processing**: Clean and prepare user input\n","2. **Intent Classification**: Determine if a function call is needed\n","3. **Function Selection**: Choose the most appropriate tool\n","4. **Parameter Extraction**: Pull relevant data from the query\n","5. **Function Execution**: Run the selected function safely\n","6. **Response Generation**: Format results naturally\n","\n","## Benefits of This Approach\n","\n","### üöÄ Enhanced Capabilities\n","- Transform simple chatbots into powerful assistants\n","- Access real-time data and external services\n","- Perform complex operations beyond text generation\n","\n","### üîí Controlled Execution\n","- Only pre-defined functions can be called\n","- Parameter validation prevents malicious inputs\n","- Error handling ensures system stability\n","\n","### üé® Natural Interaction\n","- Users don't need to learn specific command syntax\n","- Conversational interface feels intuitive\n","- Flexible input handling accommodates various phrasings\n","\n","### üìà Scalability\n","- Easy to add new functions and capabilities\n","- Modular design supports team development\n","- Can integrate with existing APIs and services\n","\n","## Use Cases\n","- **Personal Assistants**: Schedule management, email handling, file organization\n","- **Customer Support**: Ticket creation, knowledge base search, status updates\n","- **Data Analysis**: Report generation, visualization, statistical analysis\n","- **Content Creation**: Research assistance, fact-checking, citation management\n","- **Development Tools**: Code analysis, testing, deployment automation\n","\n","## Best Practices Implemented\n","- **Error Handling**: Graceful failure modes with helpful error messages\n","- **Input Validation**: Sanitize and validate all inputs before processing\n","- **Rate Limiting**: Prevent abuse of external APIs\n","- **Logging**: Track function calls for debugging and analysis\n","- **Security**: Sandboxed execution environment for safety\n","\n","This implementation serves as a foundation for building sophisticated AI assistants that can interact with the real world while maintaining safety and reliability."],"metadata":{"id":"OOny_fvlOFlp"}},{"cell_type":"markdown","source":["## üîß Step 1: Install Dependencies\n","\n","We'll use these libraries to build our function-calling system:\n","\n","- **`openai`**: Connect with OpenAI's API to use their models\n","- **`accelerate`**: Optimize model performance and GPU usage\n","- **`beautifulsoup4`**: Parse HTML for web scraping\n","- **`requests`**: Make HTTP requests to APIs and websites\n","\n","These enable our LLM to analyze text, make decisions, and interact with external services like web search."],"metadata":{"id":"KlVeBB5hOIRB"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"iiCqnb2INcld"},"outputs":[],"source":["!pip install requests==2.32.3 beautifulsoup4 openai --upgrade --quiet"]},{"cell_type":"markdown","source":["## üöÄ Setup & Initialize OpenAI Function Calling System\n","\n","This section sets up all the dependencies and establishes a connection to OpenAI's API for professional-grade function calling.\n","\n","### What We're Building\n","We're creating an AI assistant that can intelligently decide when to use tools (functions) based on natural language input - the same technology that powers ChatGPT's function calling capabilities.\n","\n","### Key Dependencies\n","- **`openai`**: Official OpenAI API client for GPT-3.5 function calling\n","- **`requests` + `beautifulsoup4`**: For real web scraping and API calls\n","- **`json`**: For parsing structured function call responses\n","- **Standard libraries**: `time`, `random`, `re` for robust web operations\n","\n","### OpenAI API Setup\n","The system initializes a connection to OpenAI's servers and tests the API key to ensure everything is working correctly. This replaces complex local model management with a simple, reliable cloud API.\n","\n","### Why This Approach?\n","- **Professional Grade**: Uses the same API that powers production AI assistants\n","- **Reliable**: No local model management or memory issues\n","- **Intelligent**: GPT-3.5/4 excel at understanding when and how to call functions\n","- **Simple**: Clean code with enterprise-level capabilities\n","\n","This foundation enables true function calling where the AI understands both **when** to use tools and **how** to extract the right parameters from natural language."],"metadata":{"id":"1PWwj6vfOOdK"}},{"cell_type":"code","source":["from openai import OpenAI\n","import json\n","import requests\n","from bs4 import BeautifulSoup\n","import warnings\n","import re\n","import time\n","import random\n","warnings.filterwarnings(\"ignore\")\n","\n","# Initialize OpenAI client with your API key\n","client = OpenAI(api_key=\"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\")  # Replace with your actual key\n","\n","print(\"üîë OpenAI client created!\")\n","print(\"üìù Get your key from: https://platform.openai.com/api-keys\")\n","\n","# Test that client works\n","try:\n","    # Simple test call\n","    test_response = client.chat.completions.create(\n","        model=\"gpt-3.5-turbo\",\n","        messages=[{\"role\": \"user\", \"content\": \"Say 'API working!'\"}],\n","        max_tokens=10\n","    )\n","    print(\"‚úÖ OpenAI API connection successful!\")\n","    print(f\"üß™ Test response: {test_response.choices[0].message.content}\")\n","except Exception as e:\n","    print(f\"‚ùå API connection failed: {e}\")\n","    print(\"üîë Make sure your API key is correct!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iRmFBMkBYVgD","executionInfo":{"status":"ok","timestamp":1753169948512,"user_tz":-240,"elapsed":2952,"user":{"displayName":"Zamzam Said","userId":"05150304630608632338"}},"outputId":"2ed7db5b-1f65-4be9-87fa-9d6060b7e363"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["üîë OpenAI client created!\n","üìù Get your key from: https://platform.openai.com/api-keys\n","‚úÖ OpenAI API connection successful!\n","üß™ Test response: API working!\n"]}]},{"cell_type":"markdown","source":["## üõ†Ô∏è Function Definitions - The AI's Available Tools\n","\n","This section defines the three core functions that our AI assistant can intelligently call based on user requests. These represent real-world capabilities that transform the AI from a simple chatbot into an interactive agent.\n","\n","### üå§Ô∏è Weather Function - Live API Integration\n","**`get_weather(city)`** connects to the wttr.in weather service to fetch real-time weather data for any city worldwide.\n","\n","**Key Features:**\n","- **Live data**: Connects to external weather API for current conditions\n","- **Formatted output**: Returns temperature, humidity, wind, and conditions\n","- **Error handling**: Graceful failure with informative messages\n","- **Global coverage**: Works for cities worldwide\n","\n","**Teaching Point:** This demonstrates how AI assistants connect to real-world data sources.\n","\n","### üîç Search Function - Production-Grade Web Scraping\n","**`search_web(query)`** implements a sophisticated web search system with enterprise-level reliability.\n","\n","**Advanced Architecture:**\n","- **Dual-engine fallback**: Brave Search ‚Üí DuckDuckGo if rate limited\n","- **Anti-blocking measures**: Realistic browser headers, random delays\n","- **Robust parsing**: Multiple CSS selectors for different website layouts\n","- **AI-powered summarization**: OpenAI processes raw search results into natural answers\n","- **Error resilience**: Multiple fallback layers ensure reliable operation\n","\n","**Why This Matters:** Real production systems need redundancy and error handling. This shows students how to build reliable, production-grade integrations that handle real-world failures gracefully.\n","\n","### üßÆ Calculate Function - Secure Code Execution\n","**`calculate(expression)`** safely evaluates mathematical expressions with security-first design.\n","\n","**Security Features:**\n","- **Input validation**: Whitelist approach - only safe characters allowed\n","- **Restricted execution**: Custom environment with no dangerous functions\n","- **Sandboxed evaluation**: Uses `eval()` safely with controlled namespace\n","- **Error containment**: All exceptions caught and handled gracefully\n","\n","**Security Lesson:** This demonstrates how to safely execute user input - a critical skill for production AI systems.\n","\n","### üèóÔ∏è Production-Ready Design Principles\n","Each function implements enterprise patterns:\n","- **Comprehensive error handling** for network failures, API limits, invalid input\n","- **Informative logging** for debugging and monitoring\n","- **Graceful degradation** when services are unavailable\n","- **Security-first mindset** to prevent exploitation\n","\n","These functions serve as the foundation for intelligent function calling - the AI will learn to select and execute them based on natural language understanding."],"metadata":{"id":"NOZNhLZZOQes"}},{"cell_type":"code","source":["def get_weather(city):\n","    \"\"\"Get weather information for a city using wttr.in API\"\"\"\n","    try:\n","        # wttr.in provides simple weather API with format parameters\n","        # %l=location, %C=condition, %t=temp, %h=humidity, %w=wind\n","        url = f\"https://wttr.in/{city}?format=%l:+%C+%t+%h+%w\"\n","        response = requests.get(url, timeout=10)\n","\n","        if response.status_code == 200:\n","            return f\"üå§Ô∏è Weather in {city}: {response.text.strip()}\"\n","        else:\n","            return f\"‚ùå Could not get weather for {city}\"\n","    except Exception as e:\n","        return f\"‚ö†Ô∏è Weather service error: {str(e)}\"\n","\n","def search_web(query):\n","    \"\"\"Internet search with dual-engine fallback system + OpenAI summarization\"\"\"\n","    import requests\n","    from bs4 import BeautifulSoup\n","    import random\n","    import time\n","\n","    def try_brave_search(query):\n","        \"\"\"Primary search engine - Brave Search\"\"\"\n","        try:\n","            print(f\"üîç Trying Brave search...\")\n","\n","            # Random delay to avoid rate limiting\n","            delay = random.uniform(1, 3)\n","            time.sleep(delay)\n","\n","            # Realistic browser headers to avoid blocking\n","            headers = {\n","                \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n","                \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n","                \"Accept-Language\": \"en-US,en;q=0.5\"\n","            }\n","\n","            # Build search URL with proper encoding\n","            search_url = f\"https://search.brave.com/search?q={requests.utils.quote(query)}\"\n","            response = requests.get(search_url, headers=headers, timeout=15)\n","\n","            print(f\"üìÑ Brave status: {response.status_code}\")\n","\n","            # Handle rate limiting - return None to trigger fallback\n","            if response.status_code == 429:\n","                print(\"üö´ Brave rate limited!\")\n","                return None, None, None\n","\n","            if response.status_code != 200:\n","                return None, None, None\n","\n","            # Parse HTML response\n","            soup = BeautifulSoup(response.text, \"html.parser\")\n","\n","            # Try multiple CSS selectors to find search results\n","            selectors = [\"div.snippet\", \"div[data-type='web']\", \".result\", \"div.fdb\"]\n","            for selector in selectors:\n","                results = soup.select(selector)\n","                if results:\n","                    result = results[0]\n","                    link_elem = result.find(\"a\")\n","                    title = link_elem.text.strip() if link_elem else \"No title\"\n","                    link = link_elem.get(\"href\") if link_elem else \"\"\n","\n","                    # Fix relative URLs\n","                    if link and not link.startswith(\"http\"):\n","                        link = \"https://search.brave.com\" + link\n","\n","                    # Extract meaningful text snippet\n","                    text = result.get_text().replace(title, \"\").strip()[:200]\n","                    print(\"‚úÖ Brave search successful\")\n","                    return title, text, link\n","\n","            print(\"‚ö†Ô∏è Brave found no results\")\n","            return None, None, None\n","\n","        except Exception as e:\n","            print(f\"‚ùå Brave error: {e}\")\n","            return None, None, None\n","\n","    def try_duckduckgo_search(query):\n","        \"\"\"Fallback search engine - DuckDuckGo\"\"\"\n","        try:\n","            print(f\"ü¶Ü Trying DuckDuckGo fallback...\")\n","\n","            headers = {\n","                \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36\"\n","            }\n","\n","            # DuckDuckGo HTML search endpoint\n","            search_url = f\"https://duckduckgo.com/html/?q={requests.utils.quote(query)}\"\n","            response = requests.get(search_url, headers=headers, timeout=15)\n","\n","            print(f\"üìÑ DuckDuckGo status: {response.status_code}\")\n","\n","            if response.status_code != 200:\n","                return None, None, None\n","\n","            soup = BeautifulSoup(response.text, \"html.parser\")\n","\n","            # DuckDuckGo-specific CSS selectors\n","            result = soup.find(\"div\", class_=\"result\") or soup.find(\"div\", class_=\"web-result\")\n","\n","            if result:\n","                link_elem = result.find(\"a\", class_=\"result__a\")\n","                title = link_elem.text.strip() if link_elem else \"No title\"\n","                link = link_elem.get(\"href\") if link_elem else \"\"\n","\n","                # Extract snippet with multiple fallback methods\n","                snippet_elem = result.find(\"a\", class_=\"result__snippet\") or result.find(\"div\", class_=\"result__snippet\")\n","                text = snippet_elem.text.strip()[:200] if snippet_elem else result.get_text().replace(title, \"\").strip()[:200]\n","\n","                print(\"‚úÖ DuckDuckGo search successful\")\n","                return title, text, link\n","\n","            print(\"‚ö†Ô∏è DuckDuckGo found no results\")\n","            return None, None, None\n","\n","        except Exception as e:\n","            print(f\"‚ùå DuckDuckGo error: {e}\")\n","            return None, None, None\n","\n","    # Main search orchestration logic\n","    print(f\"üîç Searching: {query}\")\n","\n","    # Try primary search engine first\n","    title, text, link = try_brave_search(query)\n","\n","    # Automatic fallback if primary fails\n","    if not title:\n","        title, text, link = try_duckduckgo_search(query)\n","\n","    # Both search engines failed\n","    if not title:\n","        return f\"‚ùå Both search engines failed for '{query}'. Try again later.\"\n","\n","    try:\n","        # Create context for OpenAI\n","        search_context = f\"Question: {query}\\nInfo: {title} - {text}\"\n","\n","        print(\"\\nüìù DEBUG - Context sent to OpenAI:\")\n","        print(\"=\" * 50)\n","        print(search_context)\n","        print(\"=\" * 50)\n","\n","        # Use OpenAI to answer the question\n","        response = client.chat.completions.create(\n","            model=\"gpt-3.5-turbo\",\n","            messages=[\n","                {\n","                    \"role\": \"system\",\n","                    \"content\": \"You are a helpful assistant that provides concise, accurate answers based on search results. Answer the user's question using the provided information.\"\n","                },\n","                {\n","                    \"role\": \"user\",\n","                    \"content\": f\"Based on this search result, please answer the question:\\n\\n{search_context}\\n\\nProvide a clear, concise answer:\"\n","                }\n","            ],\n","            max_tokens=100,\n","            temperature=0.3  # Low temperature for factual responses\n","        )\n","\n","        # Get OpenAI's answer\n","        answer = response.choices[0].message.content.strip()\n","\n","        print(f\"üß† OpenAI generated: {answer}\")\n","\n","        # Format final response with source link\n","        if link:\n","            return f\"üîç {answer}\\nüîó {link}\"\n","        else:\n","            return f\"üîç {answer}\"\n","\n","    except Exception as e:\n","        print(f\"‚ùå OpenAI summarization error: {e}\")\n","        # Fallback to just returning the raw search result\n","        return f\"üîç Found: {title}\\n{text[:100]}...\\nüîó {link if link else 'No link'}\"\n","\n","print(\"üîß Search function updated - Your web scraping + OpenAI summarization!\")\n","\n","def calculate(expression):\n","    \"\"\"Safely evaluate mathematical expressions with security restrictions\"\"\"\n","    try:\n","        # Define allowed characters for security\n","        allowed_chars = set('0123456789+-*/.() ')\n","        allowed_functions = ['sqrt', 'pow', 'abs']\n","\n","        # Security check: only allow safe mathematical operations\n","        if not all(c in allowed_chars or any(f in expression for f in allowed_functions) for c in expression):\n","            return \"‚ùå Only basic math operations are allowed (numbers, +, -, *, /, (), sqrt, pow, abs)\"\n","\n","        # Create restricted execution environment\n","        import math\n","        safe_dict = {\n","            '__builtins__': {},  # Remove all built-in functions\n","            'sqrt': math.sqrt,   # Only allow specific math functions\n","            'pow': math.pow,\n","            'abs': abs,\n","        }\n","\n","        # Safely evaluate the expression\n","        result = eval(expression, safe_dict)\n","        return f\"üßÆ {expression} = {result}\"\n","\n","    except Exception as e:\n","        return f\"‚ö†Ô∏è Calculation error: {str(e)}\"\n","\n","print(\"‚úÖ Functions defined!\")"],"metadata":{"id":"JrlXPcOGOQCt","colab":{"base_uri":"https://localhost:8080/"},"outputId":"14ec30f8-fd79-4755-88bb-b35212e66ef9","executionInfo":{"status":"ok","timestamp":1753169952023,"user_tz":-240,"elapsed":131,"user":{"displayName":"Zamzam Said","userId":"05150304630608632338"}}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["üîß Search function updated - Your web scraping + OpenAI summarization!\n","‚úÖ Functions defined!\n"]}]},{"cell_type":"markdown","source":["## üìã Function Registry & OpenAI Schema Definitions\n","\n","This critical section creates the bridge between our Python functions and OpenAI's function calling system. It demonstrates how modern AI systems communicate available tools to language models.\n","\n","### üèóÔ∏è Function Registry - The Security Layer\n","\n","The AVAILABLE_FUNCTIONS dictionary serves as a **security whitelist** - only functions explicitly registered here can be executed by the AI. This prevents arbitrary code execution and ensures controlled, safe function calling.\n","\n","**Key Benefits:**\n","- **Security**: No function can be called unless explicitly allowed\n","- **Maintainability**: Easy to add/remove functions centrally\n","- **Debugging**: Clear mapping between names and implementations\n","\n","### ü§ñ OpenAI Function Schemas - Teaching the AI About Tools\n","\n","The openai_functions array uses **JSON Schema format** to describe each function to GPT. This is how we \"teach\" the AI about available tools.\n","\n","#### üìñ How GPT Reads Function Schemas\n","\n","When you send a message to OpenAI with functions attached, GPT analyzes:\n","\n","1. **Function Purpose**: \"description\" tells GPT what the function does\n","2. **Parameter Structure**: \"parameters\" defines what inputs are needed\n","3. **Data Types**: \"type\": \"string\" tells GPT the parameter format\n","4. **Requirements**: \"required\": [\"city\"] indicates mandatory parameters\n","5. **Examples**: Description hints like \"Math like '15 * 7 + 254'\" guide parameter formatting\n","\n","#### üîç Deep Dive: JSON Schema Structure\n","\n","Each function schema contains:\n","- **name**: Function identifier (must match registry)\n","- **description**: What it does (GPT reads this to understand purpose)\n","- **parameters**: Object defining the input structure\n","  - **type**: \"object\" means parameters are a dictionary\n","  - **properties**: Defines each parameter with type and description\n","  - **required**: Array of mandatory parameter names\n","\n","#### üß† GPT's Decision Process\n","\n","When a user says \"What's the weather in Tokyo?\", GPT:\n","\n","1. **Scans available functions**: Reads all description fields\n","2. **Matches intent**: \"weather\" maps to get_weather function\n","3. **Extracts parameters**: Identifies \"Tokyo\" as the city\n","4. **Validates format**: Ensures \"Tokyo\" is a string (type validation)\n","5. **Structures the call**: Creates {\"city\": \"Tokyo\"} parameter object\n","\n","#### üéØ Why This Format Matters\n","\n","**Standard Protocol**: This JSON Schema format is the industry standard for AI function calling:\n","- Used by OpenAI, Anthropic, Google, Microsoft\n","- Enables interoperability between AI systems\n","- Provides clear contracts between AI and functions\n","\n","**Type Safety**: The schema provides runtime validation:\n","- GPT knows city must be a string, not a number\n","- Required parameters are enforced\n","- Invalid calls are caught before execution\n","\n","**Documentation**: Descriptions serve dual purposes:\n","- **For GPT**: Guides decision-making and parameter extraction\n","- **For Developers**: Self-documenting API specification\n","\n","#### üí° Best Practices Demonstrated\n","\n","1. **Clear Descriptions**: \"Get current weather for a city\" is specific and actionable\n","2. **Example Formats**: \"Math like '15 * 7 + 254'\" shows GPT the expected format\n","3. **Precise Types**: \"string\" is more specific than generic \"any\"\n","4. **Required Fields**: Explicitly marking mandatory parameters prevents errors\n","\n","#### üîÑ The Complete Flow\n","\n","User Input ‚Üí GPT reads schemas ‚Üí Decides function ‚Üí Extracts parameters ‚Üí Validates types ‚Üí Returns structured call ‚Üí Our system executes ‚Üí Returns result\n","\n","This schema-driven approach transforms natural language into structured function calls, enabling reliable human-AI-system interaction at scale.\n","\n","### üöÄ Production Impact\n","\n","This pattern powers:\n","- **ChatGPT Plugins**: Same schema format\n","- **GitHub Copilot**: Function suggestions\n","- **Enterprise AI**: Controlled tool access\n","- **AI Assistants**: Safe, structured interactions\n","\n","Students are learning the exact same patterns used in production AI systems worldwide."],"metadata":{"id":"vygAA8yGhTy0"}},{"cell_type":"code","source":["# Function registry - Security whitelist of callable functions\n","# This dictionary maps function names (strings) to actual Python function objects\n","# Only functions listed here can be executed by the AI - prevents arbitrary code execution\n","AVAILABLE_FUNCTIONS = {\n","    'get_weather': get_weather,    # Maps \"get_weather\" string to actual function\n","    'search_web': search_web,      # Maps \"search_web\" string to actual function\n","    'calculate': calculate         # Maps \"calculate\" string to actual function\n","}\n","\n","# OpenAI Function Schemas - Teaching GPT about available tools\n","# This array describes each function to OpenAI in JSON Schema format\n","# GPT reads these schemas to understand what functions exist and how to use them\n","openai_functions = [\n","    {\n","        # Weather function schema\n","        \"name\": \"get_weather\",                              # Function identifier (must match registry key)\n","        \"description\": \"Get current weather for a city\",    # What GPT reads to understand function purpose\n","        \"parameters\": {                                     # Input specification for this function\n","            \"type\": \"object\",                               # Parameters are passed as a dictionary/object\n","            \"properties\": {                                 # Define each parameter\n","                \"city\": {                                   # Parameter name\n","                    \"type\": \"string\",                       # Data type - GPT knows this must be text\n","                    \"description\": \"City name like 'New York City'\"  # Guides GPT on format/examples\n","                }\n","            },\n","            \"required\": [\"city\"]                            # Which parameters are mandatory\n","        }\n","    },\n","    {\n","        # Web search function schema\n","        \"name\": \"search_web\",                               # Function identifier\n","        \"description\": \"Search the internet for information\",  # Purpose description for GPT\n","        \"parameters\": {\n","            \"type\": \"object\",                               # Parameters as dictionary\n","            \"properties\": {\n","                \"query\": {                                  # Parameter name\n","                    \"type\": \"string\",                       # Must be text\n","                    \"description\": \"What to search for\"    # Helps GPT understand what to extract\n","                }\n","            },\n","            \"required\": [\"query\"]                           # Query parameter is mandatory\n","        }\n","    },\n","    {\n","        # Math calculation function schema\n","        \"name\": \"calculate\",                                # Function identifier\n","        \"description\": \"Do math calculations\",             # Purpose for GPT understanding\n","        \"parameters\": {\n","            \"type\": \"object\",                               # Parameters as dictionary\n","            \"properties\": {\n","                \"expression\": {                             # Parameter name\n","                    \"type\": \"string\",                       # Must be text (math expression as string)\n","                    \"description\": \"Math like '15 * 7 + 254'\"  # Example format for GPT guidance\n","                }\n","            },\n","            \"required\": [\"expression\"]                      # Expression parameter is mandatory\n","        }\n","    }\n","]\n","\n","print(\"üìã OpenAI function definitions ready!\")\n","\n","# How this works:\n","# 1. User sends message: \"What's the weather in Tokyo?\"\n","# 2. OpenAI reads the schemas above and matches intent to get_weather function\n","# 3. OpenAI extracts \"Tokyo\" as the city parameter based on schema guidance\n","# 4. OpenAI returns: {\"name\": \"get_weather\", \"arguments\": {\"city\": \"Tokyo\"}}\n","# 5. Our system looks up get_weather in AVAILABLE_FUNCTIONS registry\n","# 6. System calls: get_weather(city=\"Tokyo\")\n","# 7. Function executes and returns weather data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-_ExwdVkaAJS","executionInfo":{"status":"ok","timestamp":1753169999037,"user_tz":-240,"elapsed":59,"user":{"displayName":"Zamzam Said","userId":"05150304630608632338"}},"outputId":"20306276-e59b-446f-fd48-a388cd63f3e6"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["üìã OpenAI function definitions ready!\n"]}]},{"cell_type":"markdown","source":["## üß† OpenAI Function Calling Parser - The AI Decision Engine\n","\n","This is the core intelligence of our system - where natural language gets transformed into structured function calls. This function implements OpenAI's native function calling API, the same technology that powers ChatGPT's tool usage.\n","\n","### How Modern AI Function Calling Works\n","\n","When a user makes a request like \"What's the weather in Tokyo?\", this system:\n","\n","1. **Sends the request to OpenAI** along with our function schemas\n","2. **GPT analyzes the intent** and matches it to available functions\n","3. **Extracts parameters intelligently** from natural language\n","4. **Returns structured function calls** or conversational responses\n","\n","### Key Technical Features\n","\n","**Native OpenAI Integration**: Uses the official `tools` parameter introduced in OpenAI's function calling API. This is the production-standard approach used by enterprise AI systems.\n","\n","**Intelligent Decision Making**: GPT-3.5 decides autonomously whether to:\n","- Call a function (and which one)\n","- Extract the right parameters from natural language\n","- Have a normal conversation when no function is needed\n","\n","**Robust Error Handling**: Includes comprehensive exception handling for API failures, network issues, and malformed responses.\n","\n","### Why This Approach is Superior\n","\n","**Compared to rule-based systems**: No complex regex patterns or keyword matching needed. GPT understands context, synonyms, and natural language variations.\n","\n","**Compared to local models**: Uses OpenAI's powerful models specifically optimized for function calling, with better accuracy and reliability than smaller local models.\n","\n","**Production Ready**: This exact pattern is used by ChatGPT, enterprise AI assistants, and thousands of production applications.\n","\n","### The Magic of \"tool_choice\": \"auto\"\n","\n","Setting `tool_choice=\"auto\"` lets OpenAI decide whether a function call is needed. GPT analyzes each message and chooses the most appropriate response - function call or natural conversation.\n","\n","This creates truly intelligent assistants that know when to use tools and when to just chat naturally."],"metadata":{"id":"_WLlG8Vrl1OM"}},{"cell_type":"code","source":["def parse_function_call(user_input):\n","    \"\"\"\n","    Core intelligence function: Uses OpenAI's native function calling API\n","    to analyze user input and decide whether to call functions or respond conversationally\n","\n","    This implements the same technology used by ChatGPT for tool usage\n","    \"\"\"\n","    try:\n","        print(f\"üß† Asking OpenAI about: '{user_input}'\")\n","\n","        # Call OpenAI's function calling API using the new v1.0+ syntax\n","        response = client.chat.completions.create(\n","            model=\"gpt-3.5-turbo\",                    # Use GPT-3.5 (or upgrade to gpt-4 for better results)\n","            messages=[                                 # Standard chat messages format\n","                {\"role\": \"user\", \"content\": user_input}\n","            ],\n","            # Key parameter: Attach our function schemas as \"tools\"\n","            # This tells GPT what functions are available and how to use them\n","            tools=[{\"type\": \"function\", \"function\": func} for func in openai_functions],\n","\n","            # \"auto\" means GPT decides whether to call a function or just chat\n","            # Other options: \"none\" (never call functions), or specific function name (force call)\n","            tool_choice=\"auto\"\n","        )\n","\n","        # Extract the response message from OpenAI\n","        message = response.choices[0].message\n","\n","        # Check if OpenAI decided to call a function\n","        if message.tool_calls:\n","            # OpenAI wants to call a function - extract the details\n","            tool_call = message.tool_calls[0]           # Get the first (and typically only) function call\n","            function_name = tool_call.function.name      # Extract function name (e.g., \"get_weather\")\n","\n","            # Parse the JSON arguments that OpenAI extracted from natural language\n","            # Example: \"weather in Tokyo\" becomes {\"city\": \"Tokyo\"}\n","            function_args = json.loads(tool_call.function.arguments)\n","\n","            print(f\"üéØ OpenAI says: Call {function_name} with {function_args}\")\n","\n","            # Return structured function call for our execution system\n","            return {\n","                \"function\": function_name,      # Which function to call\n","                \"parameters\": function_args     # What parameters to pass\n","            }\n","        else:\n","            # No function call needed - OpenAI wants to respond conversationally\n","            print(\"üí¨ OpenAI says: Just conversation\")\n","            return {\n","                \"function\": \"none\",             # No function to execute\n","                \"parameters\": {},               # No parameters needed\n","                \"response\": message.content     # OpenAI's conversational response\n","            }\n","\n","    except Exception as e:\n","        # Handle any errors (API failures, network issues, parsing errors)\n","        print(f\"‚ùå Error: {e}\")\n","        return {\"function\": \"none\", \"parameters\": {}}\n","\n","print(\"‚úÖ OpenAI function calling ready (NEW API)!\")\n","\n","# This function transforms natural language like:\n","# \"What's the weather in New York City?\"\n","# Into structured calls like:\n","# {\"function\": \"get_weather\", \"parameters\": {\"city\": \"New York City\"}}\n","#\n","# The magic happens in OpenAI's servers - GPT reads our function schemas,\n","# understands the user's intent, and extracts the right parameters automatically!"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pWWrGJDgaC27","executionInfo":{"status":"ok","timestamp":1753167689052,"user_tz":-240,"elapsed":49,"user":{"displayName":"Zamzam Said","userId":"05150304630608632338"}},"outputId":"7f7fcbfe-8328-48f8-935a-08b022ad43b3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ OpenAI function calling ready (NEW API)!\n"]}]},{"cell_type":"markdown","source":["## ‚ö° Function Executor - Safe Code Execution Engine\n","\n","This function serves as the secure execution layer that takes OpenAI's structured function calls and safely executes them. It implements enterprise-level security patterns to prevent unauthorized code execution while enabling powerful AI-driven automation.\n","\n","### The Execution Security Model\n","\n","**Whitelist Validation**: Only functions explicitly registered in `AVAILABLE_FUNCTIONS` can be executed. This prevents injection attacks where malicious users might try to call unauthorized functions.\n","\n","**Parameter Unpacking**: Uses Python's `**parameters` syntax to safely pass extracted parameters as keyword arguments. This approach is much safer than string-based code execution methods like `eval()`.\n","\n","**Exception Isolation**: Each function call is wrapped in try-catch blocks to prevent one failure from crashing the entire system.\n","\n","### Dual Response Handling\n","\n","The executor intelligently handles two types of responses:\n","\n","1. **Function Execution**: When OpenAI determines a tool is needed, executes the appropriate function with extracted parameters\n","2. **Conversational Responses**: When no function is needed, returns OpenAI's natural language response directly\n","\n","This dual capability enables seamless transitions between tool usage and natural conversation - the hallmark of modern AI assistants.\n","\n","### Production Safety Patterns\n","\n","**Registry Validation**: Every function call is validated against the security registry before execution - no exceptions.\n","\n","**Graceful Error Handling**: Function failures return user-friendly error messages rather than system crashes or exposed stack traces.\n","\n","**Parameter Validation**: The `**parameters` unpacking automatically validates parameter names against function signatures, preventing parameter injection attacks.\n","\n","### Why This Architecture Matters\n","\n","This execution pattern is used by:\n","- **ChatGPT Plugins**: Same security model for third-party integrations\n","- **Enterprise AI**: Safe function calling in production environments\n","- **AI Agents**: Controlled automation with security boundaries\n","- **API Gateways**: Validated request routing and execution\n","\n","Students are learning production-grade security patterns used in real AI systems handling millions of requests daily."],"metadata":{"id":"ScN-V6sKnHPF"}},{"cell_type":"code","source":["def execute_function_call(function_call):\n","    \"\"\"\n","    Secure function execution engine - takes structured function calls from OpenAI\n","    and safely executes them with comprehensive security validation\n","\n","    This implements enterprise-grade security patterns used in production AI systems\n","    \"\"\"\n","\n","    # Extract function details from OpenAI's structured response\n","    function_name = function_call.get(\"function\")        # Which function to call (e.g., \"get_weather\")\n","    parameters = function_call.get(\"parameters\", {})     # Parameters to pass (e.g., {\"city\": \"Tokyo\"})\n","\n","    print(f\"üéØ Running: {function_name}\")\n","\n","    # Handle conversational responses (when no function is needed)\n","    if function_name == \"none\":\n","        # Check if OpenAI provided a conversational response\n","        if \"response\" in function_call:\n","            return function_call[\"response\"]             # Return OpenAI's chat response directly\n","        else:\n","            # Fallback message when no response is provided\n","            return \"Hi! I can help with weather, search, or math.\"\n","\n","    # SECURITY VALIDATION: Only execute functions in our approved registry\n","    # This is the critical security boundary - prevents arbitrary code execution\n","    if function_name in AVAILABLE_FUNCTIONS:\n","        try:\n","            # Get the actual function object from our secure registry\n","            function = AVAILABLE_FUNCTIONS[function_name]\n","\n","            # SAFE EXECUTION: Use **parameters to unpack arguments\n","            # This is much safer than eval() or exec() - Python validates parameter names\n","            # Example: function(**{\"city\": \"Tokyo\"}) becomes function(city=\"Tokyo\")\n","            result = function(**parameters)\n","\n","            return result                                # Return the function's output\n","\n","        except Exception as e:\n","            # Catch and contain any function execution errors\n","            # Returns user-friendly message instead of system crash\n","            return f\"‚ùå Error: {e}\"\n","    else:\n","        # Security violation: attempted to call unregistered function\n","        # This should never happen with properly configured OpenAI schemas\n","        return f\"‚ùå Unknown function: {function_name}\"\n","\n","print(\"‚úÖ Function executor ready!\")\n","\n","# Security Flow Example:\n","# 1. OpenAI returns: {\"function\": \"get_weather\", \"parameters\": {\"city\": \"Tokyo\"}}\n","# 2. Executor validates \"get_weather\" exists in AVAILABLE_FUNCTIONS ‚úÖ\n","# 3. Executor calls: get_weather(city=\"Tokyo\") using safe parameter unpacking\n","# 4. Function executes and returns weather data\n","# 5. Result is returned to user\n","#\n","# If someone tried to call an unauthorized function:\n","# 1. OpenAI returns: {\"function\": \"delete_files\", \"parameters\": {...}}\n","# 2. Executor checks registry - \"delete_files\" not found ‚ùå\n","# 3. Returns error message instead of executing dangerous code\n","# 4. System remains secure"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dZRaV1lraE1f","executionInfo":{"status":"ok","timestamp":1753167693927,"user_tz":-240,"elapsed":11,"user":{"displayName":"Zamzam Said","userId":"05150304630608632338"}},"outputId":"8488361c-b402-4b92-bb9e-7ff397afba69"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Function executor ready!\n"]}]},{"cell_type":"markdown","source":["## ü§ñ Smart Assistant Orchestrator - The Complete AI System\n","\n","This is the main interface that brings everything together into a complete AI assistant. Despite its simplicity, this function represents the culmination of modern AI architecture - transforming natural language into intelligent actions.\n","\n","### The Power of Simplicity\n","\n","The elegance of this function lies in its simplicity. In just a few lines, it:\n","\n","1. **Receives natural language input** from users\n","2. **Delegates intelligence** to OpenAI for decision-making\n","3. **Executes actions safely** through our secure function system\n","4. **Returns results** in a user-friendly format\n","\n","### Two-Stage AI Pipeline\n","\n","**Stage 1 - Intelligence Layer**: `parse_function_call()` uses GPT to understand intent and extract parameters from natural language. This is where the \"thinking\" happens.\n","\n","**Stage 2 - Execution Layer**: `execute_function_call()` safely runs the chosen function with extracted parameters. This is where the \"doing\" happens.\n","\n","This separation of concerns creates a robust, maintainable architecture used in production AI systems worldwide.\n","\n","### What Makes This \"Smart\"\n","\n","**Natural Language Understanding**: Users don't need to learn commands or syntax - they speak naturally and the AI understands.\n","\n","**Context Awareness**: The system handles everything from simple calculations to complex web searches to casual conversation.\n","\n","**Intelligent Routing**: Automatically decides whether to:\n","- Call weather APIs for \"What's it like in Paris?\"\n","- Search the web for \"Best restaurants in Tokyo\"\n","- Do math for \"Calculate 15 * 7 + 254\"  \n","- Chat normally for \"Hello, how are you?\"\n","\n","### Production Architecture Patterns\n","\n","This orchestrator implements key enterprise patterns:\n","\n","- **Single Responsibility**: Each function has one clear job\n","- **Dependency Injection**: Uses composed functions rather than tight coupling\n","- **Error Boundaries**: Failures are contained and handled gracefully\n","- **Separation of Concerns**: Intelligence separate from execution\n","\n","### Real-World Impact\n","\n","This exact pattern powers:\n","- **ChatGPT**: Same orchestration model with function calling\n","- **Virtual Assistants**: Siri, Alexa, Google Assistant use similar pipelines\n","- **Enterprise Chatbots**: Customer service and internal tools\n","- **AI Agents**: Automated workflows and business processes\n","\n","You have built the core architecture that runs billion-dollar AI systems."],"metadata":{"id":"QG1xxq_yn8Ux"}},{"cell_type":"code","source":["def smart_assistant(user_input):\n","    \"\"\"\n","    Main orchestration function - The complete AI assistant interface\n","\n","    This function represents the entire AI system in action:\n","    - Takes natural language input\n","    - Uses AI for intelligent decision-making\n","    - Executes functions safely\n","    - Returns results naturally\n","\n","    This is the same architectural pattern used by ChatGPT, Alexa, and enterprise AI systems\n","    \"\"\"\n","\n","    # Display user input with clear visual formatting\n","    print(f\"ü§ñ You said: '{user_input}'\")\n","    print(\"-\" * 40)                                      # Visual separator for clarity\n","\n","    # STAGE 1: INTELLIGENCE LAYER\n","    # Send user input to OpenAI for intelligent analysis\n","    # GPT will decide: Should I call a function? Which one? What parameters?\n","    function_call = parse_function_call(user_input)\n","\n","    # STAGE 2: EXECUTION LAYER\n","    # Take OpenAI's decision and execute it safely\n","    # This handles both function calls and conversational responses\n","    result = execute_function_call(function_call)\n","\n","    # Return the final result to the user\n","    return result\n","\n","print(\"ü§ñ Smart assistant ready!\")\n","\n","# Complete User Journey Example:\n","#\n","# User says: \"What's the weather in New York City?\"\n","# ‚Üì\n","# 1. smart_assistant() receives the input\n","# 2. parse_function_call() sends to OpenAI:\n","#    - GPT reads function schemas\n","#    - Matches \"weather\" intent to get_weather function\n","#    - Extracts \"New York City\" as city parameter\n","#    - Returns: {\"function\": \"get_weather\", \"parameters\": {\"city\": \"New York City\"}}\n","# 3. execute_function_call() processes the decision:\n","#    - Validates get_weather exists in registry ‚úÖ\n","#    - Calls get_weather(city=\"New York City\")\n","#    - Returns: \"üå§Ô∏è Weather in New York City: Sunny, 22¬∞C, Light breeze\"\n","# 4. smart_assistant() returns the weather data to user\n","#\n","# The user gets natural, helpful responses without knowing anything about\n","# function calling, APIs, or the complex orchestration happening behind the scenes!"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MG2xBC5FaGm9","executionInfo":{"status":"ok","timestamp":1753167701905,"user_tz":-240,"elapsed":6,"user":{"displayName":"Zamzam Said","userId":"05150304630608632338"}},"outputId":"f323a318-2040-49f4-8a52-54b82b85908f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ü§ñ Smart assistant ready!\n"]}]},{"cell_type":"code","source":["smart_assistant(\"What's the weather in New York City?\")"],"metadata":{"id":"tTXN0jhR8D55","executionInfo":{"status":"ok","timestamp":1753167737530,"user_tz":-240,"elapsed":2233,"user":{"displayName":"Zamzam Said","userId":"05150304630608632338"}},"outputId":"cbbdbf10-b090-48c8-fc25-27def11818f8","colab":{"base_uri":"https://localhost:8080/","height":122}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ü§ñ You said: 'What's the weather in New York City?'\n","----------------------------------------\n","üß† Asking OpenAI about: 'What's the weather in New York City?'\n","üéØ OpenAI says: Call get_weather with {'city': 'New York City'}\n","üéØ Running: get_weather\n"]},{"output_type":"execute_result","data":{"text/plain":["'üå§Ô∏è Weather in New York City: New York City: Overcast +82¬∞F 33% ‚Üì13mph'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["## üß™ Step 7: System Testing - Comprehensive Function Calling Demo\n","\n","This testing suite demonstrates the complete AI assistant in action across all supported capabilities. Each test case is carefully designed to validate different aspects of the function calling system.\n","\n","### Test Case Design Philosophy\n","\n","**Comprehensive Coverage**: Tests every function type plus conversational responses to ensure the system handles the full spectrum of user interactions.\n","\n","**Real-World Scenarios**: Uses practical queries that users would actually ask, not artificial test cases.\n","\n","**Parameter Extraction Validation**: Each query tests the system's ability to extract relevant parameters from natural language.\n","\n","### What Each Test Validates\n","\n","**Weather Query**: Tests OpenAI's ability to:\n","- Recognize weather-related intent\n","- Extract city names from natural language\n","- Handle location-specific API calls\n","\n","**Search Query**: Validates the most complex workflow:\n","- Intent classification for information seeking\n","- Query parameter extraction and cleaning\n","- Web scraping + AI summarization pipeline\n","- Dual OpenAI API call coordination\n","\n","**Conversational Input**: Ensures the system knows when NOT to call functions:\n","- Recognizes casual greetings\n","- Returns natural conversational responses\n","- Maintains friendly AI personality\n","\n","**Mathematical Calculation**: Tests structured parameter extraction:\n","- Identifies mathematical expressions\n","- Passes complete expressions to secure calculator\n","- Handles operator precedence correctly\n","\n","### The Complete Pipeline in Action\n","\n","Each test query flows through the entire system architecture:\n","\n","1. **Natural Language Input**: Raw user text\n","2. **AI Intent Classification**: OpenAI analyzes and decides function vs. conversation\n","3. **Parameter Extraction**: Intelligent extraction of relevant data\n","4. **Security Validation**: Registry check and safe execution\n","5. **Function Execution**: Real API calls, calculations, or web operations\n","6. **Formatted Response**: User-friendly results\n","\n","### Production Testing Principles\n","\n","**Boundary Testing**: Includes edge cases like simple greetings that shouldn't trigger functions.\n","\n","**Error Resilience**: System gracefully handles various input types without crashing.\n","\n","**User Experience Focus**: Results are formatted for human readability, not just technical accuracy.\n","\n","This test suite demonstrates a production-ready AI assistant capable of seamless interaction between natural conversation and intelligent tool usage."],"metadata":{"id":"u-mKzFsTUBhq"}},{"cell_type":"code","source":["# Test the complete function calling system\n","print(\"üß™ Testing the improved function calling system:\\n\")\n","\n","# Comprehensive test queries designed to validate all system capabilities\n","# Each query tests different aspects of the AI assistant\n","test_queries = [\n","    \"What's the weather like in Salalah?\",              # Weather function test\n","    # Tests:\n","    # - Weather intent recognition\n","    # - City name extraction (\"Salalah\")\n","    # - Real-time API integration\n","    # - Geographic location handling\n","\n","    \"Search the internet for what is the best movie ever made?\",    # Web search test\n","    # Tests:\n","    # - Search intent classification\n","    # - Query parameter extraction and cleaning\n","    # - Complex dual-API workflow (function calling + summarization)\n","    # - Web scraping with fallback systems\n","\n","    \"Hi\",                                               # Conversational test\n","    # Tests:\n","    # - Non-function intent recognition\n","    # - Conversational response generation\n","    # - System's ability to know when NOT to call functions\n","    # - Natural AI personality\n","\n","    \"Calculate 15 * 7 + 254\",                          # Math calculation test\n","    # Tests:\n","    # - Mathematical intent recognition\n","    # - Complete expression extraction\n","    # - Secure code execution\n","    # - Operator precedence handling\n","]\n","\n","# Execute comprehensive test suite\n","# Run each test query through the complete system pipeline\n","for query in test_queries:\n","    print(f\"User: {query}\")\n","\n","    # Process the query through our complete AI pipeline:\n","    # STAGE 1: Natural language input processing\n","    # STAGE 2: OpenAI-powered intent classification\n","    # STAGE 3: Intelligent parameter extraction\n","    # STAGE 4: Security validation and registry lookup\n","    # STAGE 5: Safe function execution or conversational response\n","    # STAGE 6: Formatted response generation\n","    response = smart_assistant(query)\n","\n","    print(f\"Assistant: {response}\")\n","    print(\"=\" * 60)  # Visual separator between test cases\n","\n","# Expected Test Results:\n","#\n","# Weather Test ‚Üí Should call get_weather(city=\"Salalah\") ‚Üí Real weather data\n","# Search Test ‚Üí Should call search_web(query=\"best movie ever made\") ‚Üí Web results + AI summary\n","# Chat Test ‚Üí Should return conversational response ‚Üí Friendly greeting\n","# Math Test ‚Üí Should call calculate(expression=\"15 * 7 + 254\") ‚Üí Mathematical result (359)\n","#\n","# This demonstrates a fully functional AI assistant that seamlessly transitions\n","# between tool usage and natural conversation based on user intent!"],"metadata":{"id":"ojy5nxMkmfo1","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d90f1d90-8a25-41fa-d7c4-1dc374e433bd","executionInfo":{"status":"ok","timestamp":1753167761873,"user_tz":-240,"elapsed":8045,"user":{"displayName":"Zamzam Said","userId":"05150304630608632338"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üß™ Testing the improved function calling system:\n","\n","User: What's the weather like in Salalah?\n","ü§ñ You said: 'What's the weather like in Salalah?'\n","----------------------------------------\n","üß† Asking OpenAI about: 'What's the weather like in Salalah?'\n","üéØ OpenAI says: Call get_weather with {'city': 'Salalah'}\n","üéØ Running: get_weather\n","Assistant: üå§Ô∏è Weather in Salalah: Salalah: Light drizzle, mist +75¬∞F 100% ‚Üó12mph\n","============================================================\n","User: Search the internet for what is the best movie ever made?\n","ü§ñ You said: 'Search the internet for what is the best movie ever made?'\n","----------------------------------------\n","üß† Asking OpenAI about: 'Search the internet for what is the best movie ever made?'\n","üéØ OpenAI says: Call search_web with {'query': 'What is the best movie ever made?'}\n","üéØ Running: search_web\n","üîç Searching: What is the best movie ever made?\n","üîç Trying Brave search...\n","‚ùå Brave error: ('Received response with content-encoding: br, but failed to decode it.', error('BrotliDecoderDecompressStream failed while processing the stream'))\n","ü¶Ü Trying DuckDuckGo fallback...\n","üìÑ DuckDuckGo status: 200\n","‚úÖ DuckDuckGo search successful\n","\n","üìù DEBUG - Context sent to OpenAI:\n","==================================================\n","Question: What is the best movie ever made?\n","Info: Top 100 Greatest Movies of All Time (The Ultimate List) - IMDb - The movies on this list are ranked according to their success (awards & nominations), their popularity, and their cinematic greatness from a directing/writing perspective. To me, accuracy when making \n","==================================================\n","üß† OpenAI generated: The best movie ever made according to the \"Top 100 Greatest Movies of All Time\" list on IMDb is subjective and varies based on individual preferences and opinions.\n","Assistant: üîç The best movie ever made according to the \"Top 100 Greatest Movies of All Time\" list on IMDb is subjective and varies based on individual preferences and opinions.\n","üîó //duckduckgo.com/l/?uddg=https%3A%2F%2Fwww.imdb.com%2Flist%2Fls055592025%2F&rut=c834ecfd058118717dadd4c4735cfb4e94fbdd3cf44b00b47f3cda8727a405a6\n","============================================================\n","User: Hi\n","ü§ñ You said: 'Hi'\n","----------------------------------------\n","üß† Asking OpenAI about: 'Hi'\n","üí¨ OpenAI says: Just conversation\n","üéØ Running: none\n","Assistant: Hello! How can I assist you today?\n","============================================================\n","User: Calculate 15 * 7 + 254\n","ü§ñ You said: 'Calculate 15 * 7 + 254'\n","----------------------------------------\n","üß† Asking OpenAI about: 'Calculate 15 * 7 + 254'\n","üéØ OpenAI says: Call calculate with {'expression': '15 * 7 + 254'}\n","üéØ Running: calculate\n","Assistant: üßÆ 15 * 7 + 254 = 359\n","============================================================\n"]}]},{"cell_type":"markdown","source":["# üöÄ 5 Advanced Enhancement Tracks\n","\n","Take your function-calling system to the next level with these improvement paths:\n","\n","## 1. **Interactive Web UI with Gradio** ‚≠ê *Beginner*\n","**Current**: Code runs in Jupyter notebook only  \n","**Enhancement**: Create a beautiful, shareable web interface using Gradio - perfect for Google Colab\n","\n","**Why Gradio**: Designed specifically for notebook environments, creates instant public URLs for sharing your AI assistant with friends, family, or employers!\n","\n","**Skills Learned**: Web interface design, user experience, sharing AI applications, rapid prototyping\n","\n","**üí° Getting Started**:\n","- Install Gradio: `!pip install gradio` (works perfectly in Colab)\n","- Create a simple chat interface in just 3-5 lines of code\n","- Wrap your `smart_assistant()` function with Gradio interface\n","- Features to add:\n","  - **Chat history**: Shows conversation flow\n","  - **Loading indicators**: \"ü§î Thinking...\" while processing\n","  - **Function indicators**: Shows when weather/search/calc is running\n","  - **Custom styling**: Make it look professional\n","- **Instant sharing**: Gradio creates public URLs automatically - share your AI with anyone!\n","- **Mobile ready**: Works perfectly on phones and tablets\n","\n","## 2. **Multi-Function Orchestration** ‚≠ê‚≠ê *Intermediate*\n","**Current**: One function per query  \n","**Enhancement**: Execute multiple functions in sequence for complex requests\n","\n","**Example**: *\"What's the weather in Tokyo and search for tourist attractions there?\"*\n","\n","**Features**: Parse multiple intents, chain function calls, combine results  \n","**Skills Learned**: Complex parsing, dependency management, result aggregation\n","\n","**üí° Getting Started**:\n","- Modify the parser to detect multiple intents using keywords (\"and\", \"then\", \"also\")\n","- Create a new function `execute_multiple_functions()` that takes a list of function calls\n","- Start simple: handle two functions connected by \"and\"\n","- Consider function dependencies (weather first, then search using that city)\n","- Combine results into a coherent response format\n","\n","## 3. **Memory & Context System** ‚≠ê‚≠ê *Intermediate*\n","**Current**: Each query is independent  \n","**Enhancement**: Remember conversation history and user preferences\n","\n","**Features**:\n","- Remember user's location for weather queries\n","- Keep search context for follow-up questions  \n","- Store calculation results for reuse\n","\n","**Skills Learned**: State management, context tracking, personalization\n","\n","**üí° Getting Started**:\n","- Create a simple `ConversationMemory` class with dictionaries for storing context\n","- Add user preferences: `{\"default_city\": \"London\", \"last_calculation\": 42}`\n","- Modify weather function to use saved city when none is specified\n","- Store conversation history in a list for follow-up questions\n","- Start with 3-5 previous messages, then expand\n","\n","## 4. **Knowledge Base with RAG System** ‚≠ê‚≠ê *Intermediate*\n","**Current**: Only searches the web for information  \n","**Enhancement**: Add a local knowledge base that can answer questions from uploaded documents\n","\n","**Example**: Upload a PDF about your company, then ask *\"What is our vacation policy?\"*\n","\n","**Features**: Document upload, text chunking, similarity search, context-aware answers\n","\n","**Skills Learned**: Document processing, vector embeddings, retrieval systems\n","\n","**üí° Getting Started**:\n","- Start with simple text files (.txt) before handling PDFs\n","- Break documents into small chunks (200-300 words each)\n","- Use basic string matching to find relevant chunks initially\n","- Create a `query_knowledge_base()` function that searches chunks\n","- Combine found chunks with GPT-2 to generate coherent answers\n","- Test with a simple FAQ document first\n","\n","## 5. **Voice Interface Integration** ‚≠ê‚≠ê *Intermediate*  \n","**Current**: Text-only chat interface  \n","**Enhancement**: Add speech-to-text and text-to-speech capabilities for natural voice conversations\n","\n","**Example**: Users can speak \"What's the weather in Dubai?\" and hear the AI respond with actual speech\n","\n","**Features**:\n","- **Speech-to-text**: Convert user voice input to text for processing\n","- **Text-to-speech**: Convert AI responses back to natural speech\n","- **Voice activity detection**: Know when user starts/stops speaking\n","- **Multiple voice options**: Choose different AI voice personalities\n","\n","**Skills Learned**: Audio processing, browser APIs, accessibility design, multimodal interfaces\n","\n","**üí° Getting Started**:\n","- Use browser's built-in Web Speech API (works great with Gradio!)\n","- Add a \"üé§ Talk\" button to your Gradio interface\n","- Implement `speech_to_text()` function using browser recognition\n","- Add `text_to_speech()` function using browser synthesis\n","- Start with English only, then expand to other languages\n","- Add voice controls: \"Stop\", \"Repeat\", \"Pause\"\n","- Test with different accents and speaking speeds\n","- Consider adding visual indicators when AI is \"listening\" vs \"speaking\"\n","- Enhance UX with sound effects for start/stop recording\n","\n","**Technical Implementation**:\n","- **Input**: Microphone ‚Üí Speech Recognition ‚Üí Text ‚Üí Your AI Assistant\n","- **Output**: AI Response ‚Üí Text-to-Speech ‚Üí Audio Playback\n","- **Gradio Integration**: Use `gr.Audio()` components for seamless voice interface\n","- **Browser Compatibility**: Works in modern Chrome, Firefox, Safari\n","- **Mobile Ready**: Perfect for phone-based AI assistant experience\n","\n","---\n","\n","## üéØ **Choose Your Path:**\n","- **Want natural conversations?** ‚Üí Start with Track 1\n","- **Ready for complex queries?** ‚Üí Try Track 2 or 3  \n","- **Building production systems?** ‚Üí Challenge yourself with Track 4 or 5\n","\n","Each track transforms your assistant from a simple tool into an intelligent, adaptive AI companion!"],"metadata":{"id":"PcyF3686F52n"}},{"cell_type":"code","source":["def parse_multiple_function_calls(user_input):\n","    print(f\"You said: '{user_input}'\")\n","    print(\"-\" * 40)\n","\n","    system_prompt = \"\"\"\n","Available functions:\n","- get_weather(city)\n","- search_web(query)\n","- calculate(expression)\n","\n","You are a smart assistant orchestrator. Given a user request, identify ALL functions to be executed in the correct order.\n","\n","Each function call should include:\n","- function (name)\n","- parameters (in JSON format)\n","- depends_on (null or previous function name)\n","\n","Always use 'calculate' for any math-related requests, and pass the whole expression as one string in 'expression'.\n","\n","Respond in this exact format:\n","[\n","  {\n","    \"function\": \"get_weather\",\n","    \"parameters\": {\"city\": \"Tokyo\"},\n","    \"depends_on\": null\n","  },\n","  {\n","    \"function\": \"search_web\",\n","    \"parameters\": {\"query\": \"tourist attractions in Tokyo\"},\n","    \"depends_on\": \"get_weather\"\n","  }\n","]\n","\"\"\"\n","\n","\n","    user_prompt = f\"User input: \\\"{user_input}\\\". Return ordered function calls.\"\n","\n","    response = client.chat.completions.create(\n","        model=\"gpt-3.5-turbo\",\n","        messages=[\n","            {\"role\": \"system\", \"content\": system_prompt.strip()},\n","            {\"role\": \"user\", \"content\": user_prompt.strip()},\n","        ],\n","        temperature=0\n","    )\n","\n","    parsed = response.choices[0].message.content.strip()\n","    return json.loads(parsed)\n"],"metadata":{"id":"yFXcEbcKO1Ke","executionInfo":{"status":"ok","timestamp":1753171865411,"user_tz":-240,"elapsed":47,"user":{"displayName":"Zamzam Said","userId":"05150304630608632338"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["def execute_multiple_function_calls(function_calls):\n","    \"\"\"\n","    Execute multiple function calls in sequence and combine the results.\n","    \"\"\"\n","    results = []\n","    for call in function_calls:\n","        func_name = call['function']\n","        params = call['parameters']\n","        result = execute_function_call({\"function\": func_name, \"parameters\": params})\n","        results.append(result)\n","    return \"\\n\\n\".join(results)\n"],"metadata":{"id":"e9fOOpD583Yi","executionInfo":{"status":"ok","timestamp":1753171868097,"user_tz":-240,"elapsed":8,"user":{"displayName":"Zamzam Said","userId":"05150304630608632338"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["def smart_assistant(user_input):\n","    calls = parse_multiple_function_calls(user_input)\n","    responses = []\n","\n","    for call in calls:\n","        fn_name = call[\"function\"]\n","        params = call[\"parameters\"]\n","        fn = AVAILABLE_FUNCTIONS.get(fn_name)\n","\n","        if fn:\n","            print(f\"üéØ Running: {fn_name}\")\n","            try:\n","                result = fn(**params)\n","\n","                if fn_name == \"get_weather\":\n","                    responses.append(f\"üå§Ô∏è Weather Info:\\n{result}\")\n","                elif fn_name == \"search_web\":\n","                    responses.append(f\"üîç Web Results:\\n{result}\")\n","                elif fn_name == \"calculate\":\n","                    responses.append(f\"üßÆ Calculation Result:\\n{result}\")\n","                else:\n","                    responses.append(result)\n","\n","            except Exception as e:\n","                responses.append(f\"‚ùå Error while running {fn_name}: {str(e)}\")\n","        else:\n","            responses.append(f\"‚ùå Function '{fn_name}' not found.\")\n","\n","    return \"\\n\\n\".join(responses)\n"],"metadata":{"id":"e9YnGamJ86_y","executionInfo":{"status":"ok","timestamp":1753171870033,"user_tz":-240,"elapsed":9,"user":{"displayName":"Zamzam Said","userId":"05150304630608632338"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["smart_assistant(\"What's the weather in Tokyo and search for tourist attractions there?\")"],"metadata":{"id":"vue-4d7C88RC","executionInfo":{"status":"ok","timestamp":1753170501608,"user_tz":-240,"elapsed":5451,"user":{"displayName":"Zamzam Said","userId":"05150304630608632338"}},"outputId":"774b7782-e92d-4889-a7f0-52edb337b76a","colab":{"base_uri":"https://localhost:8080/","height":437}},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["You said: 'What's the weather in Tokyo and search for tourist attractions there?'\n","----------------------------------------\n","üéØ Running: get_weather\n","üéØ Running: search_web\n","üîç Searching: tourist attractions in Tokyo\n","üîç Trying Brave search...\n","‚ùå Brave error: ('Received response with content-encoding: br, but failed to decode it.', error('BrotliDecoderDecompressStream failed while processing the stream'))\n","ü¶Ü Trying DuckDuckGo fallback...\n","üìÑ DuckDuckGo status: 200\n","‚úÖ DuckDuckGo search successful\n","\n","üìù DEBUG - Context sent to OpenAI:\n","==================================================\n","Question: tourist attractions in Tokyo\n","Info: THE 15 BEST Things to Do in Tokyo (2025) - Must-See Attractions - Things to Do in Tokyo, Japan: See Tripadvisor's 1,752,318 traveler reviews and photos of Tokyo tourist attractions. Find what to do today, this weekend, or in July. We have reviews of the best places \n","==================================================\n","üß† OpenAI generated: Some popular tourist attractions in Tokyo include Senso-ji Temple, Tokyo Disneyland, Tsukiji Fish Market, Meiji Shrine, and the Tokyo Skytree.\n"]},{"output_type":"execute_result","data":{"text/plain":["'üå§Ô∏è Weather Info:\\nüå§Ô∏è Weather in Tokyo: Tokyo: Partly cloudy +28¬∞C 84% ‚Üó17km/h\\n\\nüîç Web Results:\\nüîç Some popular tourist attractions in Tokyo include Senso-ji Temple, Tokyo Disneyland, Tsukiji Fish Market, Meiji Shrine, and the Tokyo Skytree.\\nüîó //duckduckgo.com/l/?uddg=https%3A%2F%2Fwww.tripadvisor.com%2FAttractions%2Dg298184%2DActivities%2DTokyo_Tokyo_Prefecture_Kanto.html&rut=58316c5c006de362977c3d182d4e8a1fff69bf66b05094337491000c71a8bc2f'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["class ConversationMemory:\n","    def __init__(self):\n","        self.preferences = {\n","            \"default_city\": None,\n","            \"last_calculation\": None,\n","        }\n","        self.history = []\n","\n","    def update(self, message):\n","        self.history.append(message)\n","        if len(self.history) > 5:\n","            self.history = self.history[-5:]\n","\n","    def get_facts(self):\n","        return \"\\n\".join(self.history[-5:])\n"],"metadata":{"id":"DkGbgynACZNY","executionInfo":{"status":"ok","timestamp":1753176606745,"user_tz":-240,"elapsed":2,"user":{"displayName":"Zamzam Said","userId":"05150304630608632338"}}},"execution_count":55,"outputs":[]},{"cell_type":"code","source":["memory = ConversationMemory()"],"metadata":{"id":"A7Qkz4zWCZQ5","executionInfo":{"status":"ok","timestamp":1753176609356,"user_tz":-240,"elapsed":3,"user":{"displayName":"Zamzam Said","userId":"05150304630608632338"}}},"execution_count":56,"outputs":[]},{"cell_type":"code","source":["def detect_and_save_fact(user_input):\n","    \"\"\"\n","    Simple check to save any personal facts.\n","    Example: \"I love coffee\" or \"My favorite sport is football\"\n","    \"\"\"\n","    patterns = [\n","        r\"i like (.+)\",\n","        r\"i love (.+)\",\n","        r\"my favorite .+ is (.+)\",\n","        r\"i (?:am|live) in (.+)\",\n","    ]\n","\n","    for p in patterns:\n","        match = re.search(p, user_input.lower())\n","        if match:\n","            fact = user_input  # ŸÜÿ≠ŸÅÿ∏ ÿßŸÑÿ¨ŸÖŸÑÿ© ŸÉŸÖÿß\n","            memory.add_fact(fact)\n","            return f\"üß† Got it! I'll remember that: \\\"{fact}\\\"\"\n","    return None\n"],"metadata":{"id":"YrpRoui2dFF4","executionInfo":{"status":"ok","timestamp":1753176611246,"user_tz":-240,"elapsed":2,"user":{"displayName":"Zamzam Said","userId":"05150304630608632338"}}},"execution_count":57,"outputs":[]},{"cell_type":"code","source":["def smart_assistant(user_input):\n","    memory.update(f\"User: {user_input}\")\n","\n","    # ‚¨ÖÔ∏è 1. ÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑŸàÿ∏ÿßÿ¶ŸÅ\n","    calls = parse_multiple_function_calls(user_input)\n","    responses = []\n","\n","    # ‚¨ÖÔ∏è 2. ÿ•ÿ∞ÿß ŸÖÿß ŸÅŸäŸá ÿ£Ÿä Ÿàÿ∏ŸäŸÅÿ© Ÿàÿßÿ∂ÿ≠ÿ© ‚Üí ŸÜŸÅÿ∞ ŸÖŸÜÿ∑ŸÇ RAG-like\n","    if not calls:\n","        facts = memory.get_facts()\n","        prompt = f\"\"\"You are a helpful assistant. The user said: \"{user_input}\".\n","Here is what you know about them:\n","{facts}\n","\n","Use this information to reply intelligently.\"\"\"\n","\n","        response = client.chat.completions.create(\n","            model=\"gpt-3.5-turbo\",\n","            messages=[\n","                {\"role\": \"system\", \"content\": \"You remember facts and reply smartly.\"},\n","                {\"role\": \"user\", \"content\": prompt}\n","            ]\n","        )\n","        answer = response.choices[0].message.content.strip()\n","        memory.update(f\"Assistant: {answer}\")\n","        return answer\n","\n","    # ‚¨ÖÔ∏è 3. ÿ•ÿ∞ÿß ŸÅŸäŸá ÿØŸàÿßŸÑ Ÿàÿßÿ∂ÿ≠ÿ©ÿå ŸÜŸÅÿ∞Ÿáÿß ŸÉÿßŸÑŸÖÿπÿ™ÿßÿØ\n","    for call in calls:\n","        fn_name = call[\"function\"]\n","        params = call[\"parameters\"]\n","\n","        # ‚öôÔ∏è ÿ™ÿπŸàŸäÿ∂ city ŸÑŸà ŸÜÿßŸÇÿµ\n","        if fn_name == \"get_weather\" and not params.get(\"city\"):\n","            default_city = memory.preferences.get(\"default_city\")\n","            if default_city:\n","                params[\"city\"] = default_city\n","\n","        # ‚öôÔ∏è ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ÿ¢ÿÆÿ± ÿπŸÖŸÑŸäÿ© ÿ≠ÿ≥ÿßÿ®Ÿäÿ© ŸÑŸà ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ ÿ∑ŸÑÿ®\n","        if fn_name == \"calculate\" and \"use_last\" in user_input.lower():\n","            last_calc = memory.preferences.get(\"last_calculation\")\n","            if last_calc:\n","                expression = f\"{last_calc} + 10\"\n","                params[\"expression\"] = expression\n","\n","        # üß† ÿßÿ≥ÿ™ÿØÿπÿßÿ° ÿßŸÑÿØÿßŸÑÿ© ŸÖŸÜ ŸÇÿßÿ¶ŸÖÿ© AVAILABLE_FUNCTIONS\n","        fn = AVAILABLE_FUNCTIONS.get(fn_name)\n","        if fn:\n","            print(f\"üéØ Running: {fn_name}\")\n","            try:\n","                result = fn(**params)\n","\n","                # üíæ ÿ™ÿÆÿ≤ŸäŸÜ ÿßŸÑŸÖÿπŸÑŸàŸÖÿßÿ™ ÿßŸÑŸÖŸáŸÖÿ© ŸÅŸä ÿßŸÑÿ∞ÿßŸÉÿ±ÿ©\n","                if fn_name == \"get_weather\":\n","                    memory.preferences[\"default_city\"] = params[\"city\"]\n","                elif fn_name == \"calculate\":\n","                    memory.preferences[\"last_calculation\"] = eval(params[\"expression\"])\n","\n","                responses.append(result)\n","                memory.update(f\"Assistant: {result}\")\n","\n","            except Exception as e:\n","                error = f\"‚ùå Error while running {fn_name}: {str(e)}\"\n","                responses.append(error)\n","                memory.update(f\"Assistant: {error}\")\n","        else:\n","            error = f\"‚ùå Function '{fn_name}' not found.\"\n","            responses.append(error)\n","            memory.update(f\"Assistant: {error}\")\n","\n","    return \"\\n\\n\".join(responses)\n"],"metadata":{"id":"PXJNW2HbCZK2","executionInfo":{"status":"ok","timestamp":1753176613899,"user_tz":-240,"elapsed":9,"user":{"displayName":"Zamzam Said","userId":"05150304630608632338"}}},"execution_count":58,"outputs":[]},{"cell_type":"code","source":["smart_assistant(\"What's the weather in Tokyo?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":87},"id":"wBFmTgI4CZIh","executionInfo":{"status":"ok","timestamp":1753176623204,"user_tz":-240,"elapsed":5441,"user":{"displayName":"Zamzam Said","userId":"05150304630608632338"}},"outputId":"34f3e4d6-fd87-445d-fdba-1226596bff26"},"execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["You said: 'What's the weather in Tokyo?'\n","----------------------------------------\n","üéØ Running: get_weather\n"]},{"output_type":"execute_result","data":{"text/plain":["'üå§Ô∏è Weather in Tokyo: Tokyo: Sunny +29¬∞C 75% ‚Üó19km/h'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":59}]},{"cell_type":"code","source":["smart_assistant(\"What's the weather like today?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":87},"id":"u0sUc7EpCY7O","executionInfo":{"status":"ok","timestamp":1753176632773,"user_tz":-240,"elapsed":6288,"user":{"displayName":"Zamzam Said","userId":"05150304630608632338"}},"outputId":"efde31fd-25b6-41a0-eee8-a17b6f6b880a"},"execution_count":60,"outputs":[{"output_type":"stream","name":"stdout","text":["You said: 'What's the weather like today?'\n","----------------------------------------\n","üéØ Running: get_weather\n"]},{"output_type":"execute_result","data":{"text/plain":["'üå§Ô∏è Weather in today: today: Sunny +28¬∞C 66% ‚Üó10km/h'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":60}]},{"cell_type":"code","source":["smart_assistant(\"Calculate x= 20 + 22\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":87},"id":"ctVhoDMQK3Lv","executionInfo":{"status":"ok","timestamp":1753176637519,"user_tz":-240,"elapsed":760,"user":{"displayName":"Zamzam Said","userId":"05150304630608632338"}},"outputId":"f8364a09-e1dd-44f4-e0da-194809f07dec"},"execution_count":61,"outputs":[{"output_type":"stream","name":"stdout","text":["You said: 'Calculate x= 20 + 22'\n","----------------------------------------\n","üéØ Running: calculate\n"]},{"output_type":"execute_result","data":{"text/plain":["'üßÆ 20 + 22 = 42'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":61}]},{"cell_type":"code","source":["smart_assistant(\"show me last Calculate\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":87},"id":"CSaFvuKjK3D8","executionInfo":{"status":"ok","timestamp":1753176980569,"user_tz":-240,"elapsed":2518,"user":{"displayName":"Zamzam Said","userId":"05150304630608632338"}},"outputId":"2b9867df-ede5-4482-f931-2438b5b19edf"},"execution_count":66,"outputs":[{"output_type":"stream","name":"stdout","text":["You said: 'show me last Calculate'\n","----------------------------------------\n","üéØ Running: calculate\n"]},{"output_type":"execute_result","data":{"text/plain":["'‚ùå Error while running calculate: invalid syntax (<string>, line 1)'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":66}]},{"cell_type":"code","source":["smart_assistant(\"My favorite color is white\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":122},"id":"CmwB_-O0bJ3P","executionInfo":{"status":"ok","timestamp":1753176650205,"user_tz":-240,"elapsed":1747,"user":{"displayName":"Zamzam Said","userId":"05150304630608632338"}},"outputId":"fd8079aa-c6aa-42d6-c808-eb9a918df531"},"execution_count":63,"outputs":[{"output_type":"stream","name":"stdout","text":["You said: 'My favorite color is white'\n","----------------------------------------\n"]},{"output_type":"execute_result","data":{"text/plain":["\"It seems like there was an error in trying to use the calculated value of x in the subsequent operation. However, thank you for sharing that your favorite color is white! It's a classic and versatile choice. If you have any other calculations or questions, feel free to ask!\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":63}]},{"cell_type":"code","source":["memory.save_fact(\"favorite_color\", \"white\")\n"],"metadata":{"id":"NdGalr4VbPdG","executionInfo":{"status":"ok","timestamp":1753175883818,"user_tz":-240,"elapsed":6,"user":{"displayName":"Zamzam Said","userId":"05150304630608632338"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["smart_assistant(\"Why did I choose this color?\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":385},"id":"v763L9RBbQgj","executionInfo":{"status":"ok","timestamp":1753176665823,"user_tz":-240,"elapsed":4096,"user":{"displayName":"Zamzam Said","userId":"05150304630608632338"}},"outputId":"3be678d6-ba43-48db-bc5b-7fb7b1616051"},"execution_count":64,"outputs":[{"output_type":"stream","name":"stdout","text":["You said: 'Why did I choose this color?'\n","----------------------------------------\n","üéØ Running: search_web\n","üîç Searching: Why did I choose this color?\n","üîç Trying Brave search...\n","‚ùå Brave error: ('Received response with content-encoding: br, but failed to decode it.', error('BrotliDecoderDecompressStream failed while processing the stream'))\n","ü¶Ü Trying DuckDuckGo fallback...\n","üìÑ DuckDuckGo status: 200\n","‚úÖ DuckDuckGo search successful\n","\n","üìù DEBUG - Context sent to OpenAI:\n","==================================================\n","Question: Why did I choose this color?\n","Info: Why Did I Choose This Color? - The Odyssey Online - The cultural connotations could be the reason why there are so many different responses to colors and why the impact that they have on the individual and the society itself vary. If you're interested \n","==================================================\n","üß† OpenAI generated: The cultural connotations of colors may influence why individuals choose specific colors and why the impact of colors varies on both individuals and society.\n"]},{"output_type":"execute_result","data":{"text/plain":["'üîç The cultural connotations of colors may influence why individuals choose specific colors and why the impact of colors varies on both individuals and society.\\nüîó //duckduckgo.com/l/?uddg=https%3A%2F%2Fwww.theodysseyonline.com%2Fchoose%2Dthis%2Dcolor&rut=177eaf9f8f5683ed5f20cb21e40e976d892662ff886c74e05d27327852fa1a83'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":64}]},{"cell_type":"code","source":["smart_assistant(\"what is my favorite color?\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":122},"id":"gStuNv1nbaIQ","executionInfo":{"status":"ok","timestamp":1753176672002,"user_tz":-240,"elapsed":1895,"user":{"displayName":"Zamzam Said","userId":"05150304630608632338"}},"outputId":"3664dc03-27e4-4d93-fa51-b481c729506b"},"execution_count":65,"outputs":[{"output_type":"stream","name":"stdout","text":["You said: 'what is my favorite color?'\n","----------------------------------------\n"]},{"output_type":"execute_result","data":{"text/plain":["\"Based on the information you've shared previously, your favorite color is white. It's known for its neutrality, purity, and simplicity, which can evoke feelings of cleanliness, peace, and simplicity. If there have been any changes or you wish to share more about your preferences, feel free to let me know!\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":65}]},{"cell_type":"code","source":["smart_assistant(\"Hi\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":105},"id":"rnMVqeGpep7a","executionInfo":{"status":"ok","timestamp":1753177512981,"user_tz":-240,"elapsed":4072,"user":{"displayName":"Zamzam Said","userId":"05150304630608632338"}},"outputId":"74900074-81e3-43cd-ebdb-252dd5b6d2b1"},"execution_count":67,"outputs":[{"output_type":"stream","name":"stdout","text":["You said: 'Hi'\n","----------------------------------------\n"]},{"output_type":"execute_result","data":{"text/plain":["\"Hello! It seems like there was an error with the last calculation. If you provide me with the details of your calculation or equation, I'll be happy to assist you in solving it accurately. Feel free to share the information or any other queries you may have!\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":67}]},{"cell_type":"code","source":["smart_assistant(\"calculate 15 * 7 + 254\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":87},"id":"wGIksdlsh3tf","executionInfo":{"status":"ok","timestamp":1753177651970,"user_tz":-240,"elapsed":1421,"user":{"displayName":"Zamzam Said","userId":"05150304630608632338"}},"outputId":"8d32ee5b-5b01-443a-adc8-c8a7455f7e8b"},"execution_count":68,"outputs":[{"output_type":"stream","name":"stdout","text":["You said: 'calculate 15 * 7 + 254'\n","----------------------------------------\n","üéØ Running: calculate\n"]},{"output_type":"execute_result","data":{"text/plain":["'üßÆ 15 * 7 + 254 = 359'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":68}]},{"cell_type":"code","source":["smart_assistant(\"what last calculate you performed?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":87},"id":"rgiknQJch3qG","executionInfo":{"status":"ok","timestamp":1753178176050,"user_tz":-240,"elapsed":710,"user":{"displayName":"Zamzam Said","userId":"05150304630608632338"}},"outputId":"e6761f58-374a-4d17-bd52-0be729a8b16e"},"execution_count":72,"outputs":[{"output_type":"stream","name":"stdout","text":["You said: 'what last calculate you performed?'\n","----------------------------------------\n","üéØ Running: calculate\n"]},{"output_type":"execute_result","data":{"text/plain":["'‚ùå Error while running calculate: invalid syntax (<string>, line 1)'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":72}]},{"cell_type":"code","source":[],"metadata":{"id":"tIbXxQNSh3nz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class ConversationMemory:\n","    def __init__(self):\n","        self.preferences = {\n","            \"default_city\": None,\n","            \"last_calculation\": None,\n","        }\n","        self.history = []\n","\n","    def update(self, message):\n","        self.history.append(message)\n","        if len(self.history) > 5:\n","            self.history = self.history[-5:]\n","\n","    def get_facts(self):\n","        return \"\\n\".join(self.history[-5:])\n"],"metadata":{"id":"saCINW3hmesh","executionInfo":{"status":"ok","timestamp":1753178925274,"user_tz":-240,"elapsed":48,"user":{"displayName":"Zamzam Said","userId":"05150304630608632338"}}},"execution_count":73,"outputs":[]},{"cell_type":"code","source":["def calculate(expression):\n","    result = eval(expression)\n","    memory.preferences[\"last_calculation\"] = result  # ÿ™ÿÆÿ≤ŸäŸÜ ÿßŸÑÿ±ŸÇŸÖ ŸÅŸÇÿ∑\n","    return f\"{expression} = {result}\"\n","\n"],"metadata":{"id":"Fezaxo6OmepG","executionInfo":{"status":"ok","timestamp":1753178927593,"user_tz":-240,"elapsed":2,"user":{"displayName":"Zamzam Said","userId":"05150304630608632338"}}},"execution_count":74,"outputs":[]},{"cell_type":"code","source":["def get_weather(city):\n","    \"\"\"Get weather information for a city using wttr.in API\"\"\"\n","    import requests\n","\n","    try:\n","        # wttr.in provides simple weather API with format parameters\n","        # %l=location, %C=condition, %t=temp, %h=humidity, %w=wind\n","        url = f\"https://wttr.in/{city}?format=%l:+%C+%t+%h+%w\"\n","        response = requests.get(url, timeout=10)\n","\n","        if response.status_code == 200:\n","            return f\"üå§Ô∏è Weather in {city}: {response.text.strip()}\"\n","        else:\n","            return f\"‚ùå Could not get weather for {city}\"\n","    except Exception as e:\n","        return f\"‚ö†Ô∏è Weather service error: {str(e)}\"\n"],"metadata":{"id":"fACYzwAfm0a0","executionInfo":{"status":"ok","timestamp":1753179351921,"user_tz":-240,"elapsed":4,"user":{"displayName":"Zamzam Said","userId":"05150304630608632338"}}},"execution_count":87,"outputs":[]},{"cell_type":"code","source":["def search_web(query):\n","    \"\"\"Internet search with dual-engine fallback system + OpenAI summarization\"\"\"\n","    import requests\n","    from bs4 import BeautifulSoup\n","    import random\n","    import time\n","\n","    def try_brave_search(query):\n","        try:\n","            print(f\"üîç Trying Brave search...\")\n","            time.sleep(random.uniform(1, 3))\n","\n","            headers = {\n","                \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\",\n","                \"Accept\": \"text/html\",\n","            }\n","            url = f\"https://search.brave.com/search?q={requests.utils.quote(query)}\"\n","            response = requests.get(url, headers=headers, timeout=15)\n","\n","            if response.status_code != 200:\n","                return None, None, None\n","\n","            soup = BeautifulSoup(response.text, \"html.parser\")\n","            selectors = [\"div.snippet\", \".result\", \"div.fdb\"]\n","            for selector in selectors:\n","                results = soup.select(selector)\n","                if results:\n","                    result = results[0]\n","                    link_elem = result.find(\"a\")\n","                    title = link_elem.text.strip() if link_elem else \"No title\"\n","                    link = link_elem.get(\"href\") if link_elem else \"\"\n","                    text = result.get_text().replace(title, \"\").strip()[:200]\n","                    return title, text, link\n","            return None, None, None\n","        except Exception:\n","            return None, None, None\n","\n","    def try_duckduckgo_search(query):\n","        try:\n","            print(f\"ü¶Ü Trying DuckDuckGo fallback...\")\n","            headers = {\"User-Agent\": \"Mozilla/5.0\"}\n","            url = f\"https://duckduckgo.com/html/?q={requests.utils.quote(query)}\"\n","            response = requests.get(url, headers=headers, timeout=15)\n","\n","            if response.status_code != 200:\n","                return None, None, None\n","\n","            soup = BeautifulSoup(response.text, \"html.parser\")\n","            result = soup.find(\"div\", class_=\"result\")\n","            if result:\n","                link_elem = result.find(\"a\", class_=\"result__a\")\n","                title = link_elem.text.strip() if link_elem else \"No title\"\n","                link = link_elem.get(\"href\") if link_elem else \"\"\n","                snippet_elem = result.find(\"a\", class_=\"result__snippet\") or result.find(\"div\", class_=\"result__snippet\")\n","                text = snippet_elem.text.strip()[:200] if snippet_elem else result.get_text().replace(title, \"\").strip()[:200]\n","                return title, text, link\n","            return None, None, None\n","        except Exception:\n","            return None, None, None\n","\n","    print(f\"üîç Searching: {query}\")\n","    title, text, link = try_brave_search(query)\n","\n","    if not title:\n","        title, text, link = try_duckduckgo_search(query)\n","\n","    if not title:\n","        return f\"‚ùå Both search engines failed for '{query}'. Try again later.\"\n","\n","    try:\n","        from openai import OpenAI\n","        client = OpenAI()\n","\n","        search_context = f\"Question: {query}\\nInfo: {title} - {text}\"\n","        response = client.chat.completions.create(\n","            model=\"gpt-3.5-turbo\",\n","            messages=[\n","                {\"role\": \"system\", \"content\": \"You are a helpful assistant that summarizes search results.\"},\n","                {\"role\": \"user\", \"content\": f\"Based on this search result, answer the question:\\n{search_context}\"}\n","            ],\n","            max_tokens=100,\n","            temperature=0.3\n","        )\n","        answer = response.choices[0].message.content.strip()\n","        return f\"üîç {answer}\\nüîó {link}\" if link else f\"üîç {answer}\"\n","    except Exception as e:\n","        return f\"üîç Found: {title}\\n{text[:100]}...\\nüîó {link if link else 'No link'}\"\n"],"metadata":{"id":"AxUPgvbXofa5","executionInfo":{"status":"ok","timestamp":1753179360182,"user_tz":-240,"elapsed":32,"user":{"displayName":"Zamzam Said","userId":"05150304630608632338"}}},"execution_count":88,"outputs":[]},{"cell_type":"code","source":["AVAILABLE_FUNCTIONS = {\n","    \"get_weather\": get_weather,\n","    \"search_web\": search_web,\n","    \"calculate\": calculate,\n","}\n"],"metadata":{"id":"W77eCB7tmemy","executionInfo":{"status":"ok","timestamp":1753179362653,"user_tz":-240,"elapsed":2,"user":{"displayName":"Zamzam Said","userId":"05150304630608632338"}}},"execution_count":89,"outputs":[]},{"cell_type":"code","source":["def parse_multiple_function_calls(user_input):\n","    print(f\"You said: '{user_input}'\")\n","    print(\"-\" * 40)\n","\n","    last_calc = memory.preferences.get(\"last_calculation\")\n","\n","    system_prompt = f\"\"\"\n","Available functions:\n","- get_weather(city)\n","- search_web(query)\n","- calculate(expression)\n","\n","You are a smart assistant orchestrator. Your job is to convert natural language into all the function calls needed in order.\n","\n","If the user refers to a previous calculation result (even using indirect words like \"that\", \"it\", \"previous result\", etc.), replace it with the actual number: {last_calc}.\n","\n","Respond ONLY in this JSON format:\n","[\n","  {{\n","    \"function\": \"calculate\",\n","    \"parameters\": {{\"expression\": \"42 * 2\"}},\n","    \"depends_on\": null\n","  }}\n","]\n","\"\"\"\n","\n","    user_prompt = f\"User input: \\\"{user_input}\\\". Return function calls in correct order.\"\n","\n","    response = client.chat.completions.create(\n","        model=\"gpt-4\",  # ŸäŸÖŸÉŸÜŸÉ ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ gpt-3.5-turbo ÿ£Ÿäÿ∂ÿßŸã\n","        messages=[\n","            {\"role\": \"system\", \"content\": system_prompt.strip()},\n","            {\"role\": \"user\", \"content\": user_prompt.strip()},\n","        ],\n","        temperature=0\n","    )\n","\n","    parsed = response.choices[0].message.content.strip()\n","    return json.loads(parsed)\n"],"metadata":{"id":"OA6BgNLXmeka","executionInfo":{"status":"ok","timestamp":1753179364586,"user_tz":-240,"elapsed":3,"user":{"displayName":"Zamzam Said","userId":"05150304630608632338"}}},"execution_count":90,"outputs":[]},{"cell_type":"code","source":["def smart_assistant(user_input):\n","    memory.update(f\"User: {user_input}\")\n","\n","    # ÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑŸàÿ∏ÿßÿ¶ŸÅ\n","    calls = parse_multiple_function_calls(user_input)\n","    responses = []\n","\n","    # ÿ•ÿ∞ÿß ŸÑŸÖ Ÿäÿ™ŸÖ ÿßŸÑÿ™ÿπÿ±ŸÅ ÿπŸÑŸâ ÿØŸàÿßŸÑÿå ŸÜŸÅÿ∞ ŸÖŸÜÿ∑ŸÇ RAG-like\n","    if not calls:\n","        facts = memory.get_facts()\n","        prompt = f\"\"\"You are a helpful assistant. The user said: \"{user_input}\".\n","Here is what you know about them:\n","{facts}\n","\n","Use this information to reply intelligently.\"\"\"\n","\n","        response = client.chat.completions.create(\n","            model=\"gpt-3.5-turbo\",\n","            messages=[\n","                {\"role\": \"system\", \"content\": \"You remember facts and reply smartly.\"},\n","                {\"role\": \"user\", \"content\": prompt}\n","            ]\n","        )\n","        answer = response.choices[0].message.content.strip()\n","        memory.update(f\"Assistant: {answer}\")\n","        return answer\n","\n","    # ÿ™ŸÜŸÅŸäÿ∞ ÿßŸÑŸàÿ∏ÿßÿ¶ŸÅ\n","    for call in calls:\n","        fn_name = call[\"function\"]\n","        params = call[\"parameters\"]\n","\n","        # ÿ™ÿπŸàŸäÿ∂ ÿßŸÑŸÖÿØŸäŸÜÿ© ÿ•ÿ∞ÿß ŸÜÿßŸÇÿµÿ©\n","        if fn_name == \"get_weather\" and not params.get(\"city\"):\n","            default_city = memory.preferences.get(\"default_city\")\n","            if default_city:\n","                params[\"city\"] = default_city\n","\n","        fn = AVAILABLE_FUNCTIONS.get(fn_name)\n","        if fn:\n","            print(f\"üéØ Running: {fn_name}\")\n","            try:\n","                result = fn(**params)\n","\n","                if fn_name == \"get_weather\":\n","                    memory.preferences[\"default_city\"] = params[\"city\"]\n","                elif fn_name == \"calculate\":\n","                    memory.preferences[\"last_calculation\"] = eval(params[\"expression\"])\n","\n","                responses.append(f\"{result}\")\n","                memory.update(f\"Assistant: {result}\")\n","\n","            except Exception as e:\n","                error = f\"‚ùå Error while running {fn_name}: {str(e)}\"\n","                responses.append(error)\n","                memory.update(f\"Assistant: {error}\")\n","        else:\n","            error = f\"‚ùå Function '{fn_name}' not found.\"\n","            responses.append(error)\n","            memory.update(f\"Assistant: {error}\")\n","\n","    return \"\\n\\n\".join(responses)\n"],"metadata":{"id":"f5j28DwRmeiR","executionInfo":{"status":"ok","timestamp":1753179367605,"user_tz":-240,"elapsed":12,"user":{"displayName":"Zamzam Said","userId":"05150304630608632338"}}},"execution_count":91,"outputs":[]},{"cell_type":"code","source":["memory = ConversationMemory()\n"],"metadata":{"id":"-EYEw76fmef6","executionInfo":{"status":"ok","timestamp":1753179371417,"user_tz":-240,"elapsed":3,"user":{"displayName":"Zamzam Said","userId":"05150304630608632338"}}},"execution_count":92,"outputs":[]},{"cell_type":"code","source":["smart_assistant(\"Calculate 20 + 22\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":87},"id":"lzD137rdmeda","executionInfo":{"status":"ok","timestamp":1753179375570,"user_tz":-240,"elapsed":2162,"user":{"displayName":"Zamzam Said","userId":"05150304630608632338"}},"outputId":"f84032df-4bfc-4b69-9bf4-2d3aa37bb9a9"},"execution_count":93,"outputs":[{"output_type":"stream","name":"stdout","text":["You said: 'Calculate 20 + 22'\n","----------------------------------------\n","üéØ Running: calculate\n"]},{"output_type":"execute_result","data":{"text/plain":["'20 + 22 = 42'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":93}]},{"cell_type":"code","source":["smart_assistant(\"Multiply that by 2\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":87},"id":"3pHbfmfrm9vo","executionInfo":{"status":"ok","timestamp":1753179379042,"user_tz":-240,"elapsed":1894,"user":{"displayName":"Zamzam Said","userId":"05150304630608632338"}},"outputId":"b12bffff-4e72-4353-ddfb-3e5a4695d562"},"execution_count":94,"outputs":[{"output_type":"stream","name":"stdout","text":["You said: 'Multiply that by 2'\n","----------------------------------------\n","üéØ Running: calculate\n"]},{"output_type":"execute_result","data":{"text/plain":["'42 * 2 = 84'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":94}]},{"cell_type":"code","source":["smart_assistant(\"what last calculate you performed?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":87},"id":"DQEc8PyFm_6P","executionInfo":{"status":"ok","timestamp":1753179383789,"user_tz":-240,"elapsed":2514,"user":{"displayName":"Zamzam Said","userId":"05150304630608632338"}},"outputId":"fe29c048-0bbc-4d80-a1c2-b46566b60fdb"},"execution_count":95,"outputs":[{"output_type":"stream","name":"stdout","text":["You said: 'what last calculate you performed?'\n","----------------------------------------\n","üéØ Running: calculate\n"]},{"output_type":"execute_result","data":{"text/plain":["'84 = 84'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":95}]},{"cell_type":"code","source":["smart_assistant(\"what is my favorite color?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":87},"id":"RA6r4R7LnIsm","executionInfo":{"status":"ok","timestamp":1753179003611,"user_tz":-240,"elapsed":1882,"user":{"displayName":"Zamzam Said","userId":"05150304630608632338"}},"outputId":"f53bc469-578a-40bc-f4c2-fede29bbf7ab"},"execution_count":83,"outputs":[{"output_type":"stream","name":"stdout","text":["You said: 'what is my favorite color?'\n","----------------------------------------\n"]},{"output_type":"execute_result","data":{"text/plain":["'Based on the information you provided, your favorite color is likely blue, as that is the number you started with in the calculation (42).'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":83}]},{"cell_type":"code","source":["smart_assistant(\"What's the weather in Tokyo?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":87},"id":"uevzl8BtnMqU","executionInfo":{"status":"ok","timestamp":1753179389524,"user_tz":-240,"elapsed":3037,"user":{"displayName":"Zamzam Said","userId":"05150304630608632338"}},"outputId":"ba64fda3-abf4-4d9f-eb02-337bea3abbd8"},"execution_count":96,"outputs":[{"output_type":"stream","name":"stdout","text":["You said: 'What's the weather in Tokyo?'\n","----------------------------------------\n","üéØ Running: get_weather\n"]},{"output_type":"execute_result","data":{"text/plain":["'üå§Ô∏è Weather in Tokyo: Tokyo: Sunny +29¬∞C 75% ‚Üó19km/h'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":96}]},{"cell_type":"code","source":["smart_assistant(\"What's the weather like today?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":87},"id":"Gn4OCVv3nWeT","executionInfo":{"status":"ok","timestamp":1753179397470,"user_tz":-240,"elapsed":4874,"user":{"displayName":"Zamzam Said","userId":"05150304630608632338"}},"outputId":"e2fe7179-d9b9-411e-f668-bd1e000baa0f"},"execution_count":97,"outputs":[{"output_type":"stream","name":"stdout","text":["You said: 'What's the weather like today?'\n","----------------------------------------\n","üéØ Running: get_weather\n"]},{"output_type":"execute_result","data":{"text/plain":["'üå§Ô∏è Weather in current_location: current_location: Partly cloudy +18¬∞C 63% ‚Üô12km/h'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":97}]},{"cell_type":"code","source":["smart_assistant(\"search for a hotel their?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":192},"id":"n4_Zjx-Snh3R","executionInfo":{"status":"ok","timestamp":1753179416465,"user_tz":-240,"elapsed":6383,"user":{"displayName":"Zamzam Said","userId":"05150304630608632338"}},"outputId":"3adeb4f3-04ec-4a7a-bc45-8bbac2c4d081"},"execution_count":98,"outputs":[{"output_type":"stream","name":"stdout","text":["You said: 'search for a hotel their?'\n","----------------------------------------\n","üéØ Running: search_web\n","üîç Searching: hotel\n","üîç Trying Brave search...\n","ü¶Ü Trying DuckDuckGo fallback...\n"]},{"output_type":"execute_result","data":{"text/plain":["'üîç Found: The 10 Best Washington, D.C. Hotels (From $93) - Booking.com\\nGreat savings on hotels in Washington, D.C., United States online. Good availability and great rates...\\nüîó //duckduckgo.com/l/?uddg=https%3A%2F%2Fwww.booking.com%2Fcity%2Fus%2Fwashington.html&rut=ee335b9f52b80c93e1b98c12224a829cb7b4c6a638c3f7a8dcbef709e825f042'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":98}]},{"cell_type":"code","source":[],"metadata":{"id":"nBK2VtFns2Mm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class ConversationMemory:\n","    def __init__(self):\n","        self.preferences = {\n","            \"default_city\": None,\n","            \"last_calculation\": None,\n","            \"last_search_topic\": None,\n","        }\n","        self.history = []\n","        self.facts = {}\n","\n","    def update(self, message):\n","        self.history.append(message)\n","        if len(self.history) > 5:\n","            self.history = self.history[-5:]\n","\n","    def get_context(self):\n","        return \"\\n\".join(self.history[-5:])\n","\n","    def get_facts(self):\n","        return \"\\n\".join(f\"{k}: {v}\" for k, v in self.preferences.items() if v)\n"],"metadata":{"id":"-BYWNKmqs2Jp","executionInfo":{"status":"ok","timestamp":1753180499602,"user_tz":-240,"elapsed":2,"user":{"displayName":"Zamzam Said","userId":"05150304630608632338"}}},"execution_count":99,"outputs":[]},{"cell_type":"code","source":["AVAILABLE_FUNCTIONS = {\n","    \"get_weather\": get_weather,\n","    \"search_web\": search_web,\n","    \"calculate\": calculate,\n","}"],"metadata":{"id":"b2jeHaj1s2G6","executionInfo":{"status":"ok","timestamp":1753180555347,"user_tz":-240,"elapsed":14,"user":{"displayName":"Zamzam Said","userId":"05150304630608632338"}}},"execution_count":100,"outputs":[]},{"cell_type":"code","source":["import re\n","\n","def parse_multiple_function_calls(user_input):\n","    calls = []\n","\n","    if \"weather\" in user_input.lower():\n","        city_match = re.search(r\"in ([A-Za-z\\s]+)\", user_input)\n","        city = city_match.group(1).strip() if city_match else None\n","        calls.append({\"function\": \"get_weather\", \"parameters\": {\"city\": city}})\n","\n","    elif \"search\" in user_input.lower() or \"places\" in user_input.lower():\n","        query_match = re.search(r\"for (.+)\", user_input)\n","        query = query_match.group(1).strip() if query_match else user_input\n","        calls.append({\"function\": \"search_web\", \"parameters\": {\"query\": query}})\n","\n","    elif \"calculate\" in user_input.lower() or re.search(r\"[\\d+\\-*/()xX=]\", user_input):\n","        expr_match = re.search(r\"calculate\\s*(.+)\", user_input.lower())\n","        expression = expr_match.group(1).strip() if expr_match else user_input\n","        calls.append({\"function\": \"calculate\", \"parameters\": {\"expression\": expression}})\n","\n","    return calls\n"],"metadata":{"id":"1eqEhcPSs2ED","executionInfo":{"status":"ok","timestamp":1753180565063,"user_tz":-240,"elapsed":40,"user":{"displayName":"Zamzam Said","userId":"05150304630608632338"}}},"execution_count":101,"outputs":[]},{"cell_type":"code","source":["memory = ConversationMemory()\n","\n","def smart_assistant(user_input):\n","    print(f\"You said: '{user_input}'\\n\" + \"-\" * 40)\n","    memory.update(f\"User: {user_input}\")\n","    calls = parse_multiple_function_calls(user_input)\n","    responses = []\n","\n","    if not calls:\n","        # üß† ÿßÿ≥ÿ™ÿÆÿØŸÖ RAG ÿ£Ÿà ÿßŸÑÿ∞ÿßŸÉÿ±ÿ©\n","        facts = memory.get_facts()\n","        return f\"ü§ñ I couldn't extract a specific task. Here's what I know:\\n{facts}\\nPlease clarify your request.\"\n","\n","    for call in calls:\n","        fn_name = call[\"function\"]\n","        params = call[\"parameters\"]\n","\n","        # ‚ûï ÿßÿ≥ÿ™ŸÉŸÖÿßŸÑ ÿßŸÑÿ∑ŸÇÿ≥ ŸÖŸÜ ÿßŸÑÿ∞ÿßŸÉÿ±ÿ©\n","        if fn_name == \"get_weather\" and not params.get(\"city\"):\n","            default_city = memory.preferences.get(\"default_city\")\n","            if default_city:\n","                params[\"city\"] = default_city\n","            else:\n","                return \"‚ùì ŸÑŸÖ ÿ™ÿ≠ÿØÿØ ÿßŸÑŸÖÿØŸäŸÜÿ©ÿå ÿ£Ÿä ŸÖÿØŸäŸÜÿ© ÿ™ŸÇÿµÿØÿü\"\n","\n","        # ‚ûï ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ÿ¢ÿÆÿ± ŸÜÿ™Ÿäÿ¨ÿ© ŸÑŸÑÿ≠ÿ≥ÿßÿ®\n","        if fn_name == \"calculate\" and \"use_last\" in user_input.lower():\n","            last_calc = memory.preferences.get(\"last_calculation\")\n","            if last_calc is not None:\n","                params[\"expression\"] = str(last_calc) + \" + 0\"\n","\n","        # ‚ûï ÿ™ÿπŸàŸäÿ∂ ÿ®ÿ≠ÿ´ ŸÖŸÅŸÇŸàÿØ\n","        if fn_name == \"search_web\" and not params.get(\"query\"):\n","            last_topic = memory.preferences.get(\"last_search_topic\")\n","            if last_topic:\n","                params[\"query\"] = last_topic\n","            else:\n","                return \"‚ùì ŸÖÿß ÿßŸÑÿ∞Ÿä ÿ™ÿ±ŸäÿØ ÿßŸÑÿ®ÿ≠ÿ´ ÿπŸÜŸáÿü\"\n","\n","        fn = AVAILABLE_FUNCTIONS.get(fn_name)\n","        if fn:\n","            print(f\"üéØ Running: {fn_name}\")\n","            try:\n","                result = fn(**params)\n","\n","                # ÿ™ÿ≠ÿØŸäÿ´ ÿßŸÑÿ∞ÿßŸÉÿ±ÿ© ÿ®ÿπÿØ ŸÉŸÑ ÿØÿßŸÑÿ©\n","                if fn_name == \"get_weather\":\n","                    city = params.get(\"city\")\n","                    if city:\n","                        memory.preferences[\"default_city\"] = city\n","\n","                elif fn_name == \"calculate\":\n","                    expression = params.get(\"expression\")\n","                    value = eval(expression)\n","                    memory.preferences[\"last_calculation\"] = value\n","\n","                elif fn_name == \"search_web\":\n","                    query = params.get(\"query\")\n","                    if query:\n","                        memory.preferences[\"last_search_topic\"] = query\n","\n","                responses.append(result)\n","                memory.update(f\"Assistant: {result}\")\n","\n","            except Exception as e:\n","                error = f\"‚ùå Error while running {fn_name}: {str(e)}\"\n","                responses.append(error)\n","                memory.update(f\"Assistant: {error}\")\n","        else:\n","            error = f\"‚ùå Function '{fn_name}' not found.\"\n","            responses.append(error)\n","            memory.update(f\"Assistant: {error}\")\n","\n","    return \"\\n\\n\".join(responses)\n"],"metadata":{"id":"YeoM-aq5s2BZ","executionInfo":{"status":"ok","timestamp":1753180572825,"user_tz":-240,"elapsed":44,"user":{"displayName":"Zamzam Said","userId":"05150304630608632338"}}},"execution_count":102,"outputs":[]},{"cell_type":"code","source":["smart_assistant(\"What's the weather in Tokyo?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":87},"id":"XKIbPlAMs1-R","executionInfo":{"status":"ok","timestamp":1753180582748,"user_tz":-240,"elapsed":409,"user":{"displayName":"Zamzam Said","userId":"05150304630608632338"}},"outputId":"d8b00ea6-5f50-45b2-84c7-d934b1796169"},"execution_count":103,"outputs":[{"output_type":"stream","name":"stdout","text":["You said: 'What's the weather in Tokyo?'\n","----------------------------------------\n","üéØ Running: get_weather\n"]},{"output_type":"execute_result","data":{"text/plain":["'üå§Ô∏è Weather in Tokyo: Tokyo: Sunny +29¬∞C 75% ‚Üó19km/h'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":103}]},{"cell_type":"code","source":["smart_assistant(\"What's the weather like today?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":87},"id":"I7I-2zJotM9H","executionInfo":{"status":"ok","timestamp":1753180592912,"user_tz":-240,"elapsed":420,"user":{"displayName":"Zamzam Said","userId":"05150304630608632338"}},"outputId":"ca288f14-8a51-4437-a34b-054401e109d0"},"execution_count":104,"outputs":[{"output_type":"stream","name":"stdout","text":["You said: 'What's the weather like today?'\n","----------------------------------------\n","üéØ Running: get_weather\n"]},{"output_type":"execute_result","data":{"text/plain":["'üå§Ô∏è Weather in Tokyo: Tokyo: Sunny +29¬∞C 75% ‚Üó19km/h'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":104}]},{"cell_type":"code","source":["smart_assistant(\"search for a hotel their?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":209},"id":"QfuDFdZ2tPk2","executionInfo":{"status":"ok","timestamp":1753180622132,"user_tz":-240,"elapsed":4547,"user":{"displayName":"Zamzam Said","userId":"05150304630608632338"}},"outputId":"2f091820-9866-4241-f6ba-dae76e637f7f"},"execution_count":105,"outputs":[{"output_type":"stream","name":"stdout","text":["You said: 'search for a hotel their?'\n","----------------------------------------\n","üéØ Running: search_web\n","üîç Searching: a hotel their?\n","üîç Trying Brave search...\n","ü¶Ü Trying DuckDuckGo fallback...\n"]},{"output_type":"execute_result","data":{"text/plain":["\"üîç Found: How to Use They're, There, and Their - Merriam-Webster\\nThey're, their, and there are among the most commonly confused homophones. Here, some tricks and exa...\\nüîó //duckduckgo.com/l/?uddg=https%3A%2F%2Fwww.merriam%2Dwebster.com%2Fgrammar%2Fhow%2Dto%2Duse%2Dtheyre%2Dthere%2Dtheir&rut=04e7ca7760bb82a3e24b4af4439a6f32b32c9554988e9cc188fa28867a83ba37\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":105}]},{"cell_type":"code","source":["smart_assistant(\"Calculate 20 + 22\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":87},"id":"sA9yuizqtXdO","executionInfo":{"status":"ok","timestamp":1753180645931,"user_tz":-240,"elapsed":46,"user":{"displayName":"Zamzam Said","userId":"05150304630608632338"}},"outputId":"67746967-9a8c-4855-ae77-80951a668545"},"execution_count":106,"outputs":[{"output_type":"stream","name":"stdout","text":["You said: 'Calculate 20 + 22'\n","----------------------------------------\n","üéØ Running: calculate\n"]},{"output_type":"execute_result","data":{"text/plain":["'20 + 22 = 42'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":106}]},{"cell_type":"code","source":["smart_assistant(\"use last and add 5\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":87},"id":"9b88uTGQtXZz","executionInfo":{"status":"ok","timestamp":1753180653295,"user_tz":-240,"elapsed":41,"user":{"displayName":"Zamzam Said","userId":"05150304630608632338"}},"outputId":"3b6f2010-f04a-4fb6-911e-006bf9d9d864"},"execution_count":107,"outputs":[{"output_type":"stream","name":"stdout","text":["You said: 'use last and add 5'\n","----------------------------------------\n","üéØ Running: calculate\n"]},{"output_type":"execute_result","data":{"text/plain":["'‚ùå Error while running calculate: invalid syntax (<string>, line 1)'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":107}]},{"cell_type":"code","source":[],"metadata":{"id":"0W4ypVRntXFo"},"execution_count":null,"outputs":[]}]}